"""Modu≈Ç: researcher - agent badawczy, synteza wiedzy z Internetu."""

import os
import re
from typing import List, Tuple

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.function_choice_behavior import (
    FunctionChoiceBehavior,
)
from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings
from semantic_kernel.contents import ChatHistory
from semantic_kernel.contents.chat_message_content import ChatMessageContent
from semantic_kernel.contents.utils.author_role import AuthorRole

from venom_core.agents.base import BaseAgent
from venom_core.execution.skills.github_skill import GitHubSkill
from venom_core.execution.skills.huggingface_skill import HuggingFaceSkill
from venom_core.execution.skills.web_skill import WebSearchSkill
from venom_core.memory.memory_skill import MemorySkill
from venom_core.utils.logger import get_logger

logger = get_logger(__name__)


def format_grounding_sources(response_metadata: dict) -> str:
    """
    Formatuje ≈∫r√≥d≈Ça z Google Grounding do czytelnej formy.

    Args:
        response_metadata: Metadane odpowiedzi z API (grounding_metadata, web_search_queries)

    Returns:
        Sformatowana sekcja ze ≈∫r√≥d≈Çami lub pusty string je≈õli brak
    """
    if not response_metadata:
        return ""

    sources = []

    # Sprawd≈∫ grounding_metadata
    grounding_metadata = response_metadata.get("grounding_metadata", {})
    if grounding_metadata and grounding_metadata.get("grounding_chunks"):
        chunks = grounding_metadata.get("grounding_chunks", [])
        for idx, chunk in enumerate(chunks, 1):
            title = chunk.get("title", "Brak tytu≈Çu")
            uri = chunk.get("uri", "")
            # Dodaj ≈∫r√≥d≈Ço tylko je≈õli ma URI (link)
            if uri:
                sources.append(f"[{idx}] {title} - {uri}")
            # Je≈õli jest tytu≈Ç ale brak URI, dodaj bez linku
            elif title and title != "Brak tytu≈Çu":
                sources.append(f"[{idx}] {title}")

    # Sprawd≈∫ web_search_queries (alternatywne ≈∫r√≥d≈Ço metadanych)
    web_queries = response_metadata.get("web_search_queries", [])
    if web_queries and not sources:
        for idx, query in enumerate(web_queries, 1):
            sources.append(f"[{idx}] Zapytanie: {query}")

    if sources:
        sources_section = "\n\n---\nüìö ≈πr√≥d≈Ça (Google Grounding):\n" + "\n".join(
            sources
        )
        return sources_section

    return ""


class ResearcherAgent(BaseAgent):
    """Agent specjalizujƒÖcy siƒô w badaniu i syntezie wiedzy z Internetu."""

    SYSTEM_PROMPT = """Jeste≈õ ekspertem badawczym (Researcher). Twoim zadaniem jest znajdowanie i synteza wiedzy z Internetu.

TWOJE NARZƒòDZIA:
- search: Wyszukaj informacje w Internecie (DuckDuckGo)
- scrape_text: Pobierz i oczy≈õƒá tre≈õƒá konkretnej strony WWW
- search_and_scrape: Wyszukaj i automatycznie pobierz tre≈õƒá z najlepszych wynik√≥w
- search_repos: Wyszukaj repozytoria na GitHub (biblioteki, narzƒôdzia)
- get_readme: Pobierz README z repozytorium GitHub
- get_trending: Znajd≈∫ popularne projekty na GitHub
- search_models: Wyszukaj modele AI na Hugging Face
- get_model_card: Pobierz szczeg√≥≈Çy modelu z Hugging Face
- search_datasets: Wyszukaj zbiory danych na Hugging Face
- memorize: Zapisz wa≈ºne informacje do pamiƒôci d≈Çugoterminowej
- recall: Przywo≈Çaj informacje z pamiƒôci

ZASADY:
1. NIE PISZESZ KODU - Twoja rola to dostarczanie FAKT√ìW i WIEDZY
2. Gdy otrzymasz pytanie:
   - Najpierw sprawd≈∫ pamiƒôƒá (recall) czy nie masz ju≈º tej informacji
   - Je≈õli nie ma w pamiƒôci, wyszukaj w Internecie (search lub search_and_scrape)
   - Przeanalizuj wyniki z 2-3 najlepszych ≈∫r√≥de≈Ç
   - Stw√≥rz ZWIƒòZ≈ÅE PODSUMOWANIE TECHNICZNE z przyk≈Çadami kodu je≈õli to stosowne
3. Po zebraniu wiedzy:
   - Zapisz wa≈ºne informacje do pamiƒôci (memorize) na przysz≈Ço≈õƒá
   - Kategoryzuj wiedzƒô odpowiednio (documentation, code_example, best_practice, etc.)
4. Je≈õli strona nie dzia≈Ça (404, timeout):
   - Spr√≥buj innego wyniku z wyszukiwania
   - NIE PRZERYWAJ ca≈Çego procesu z powodu jednego b≈Çƒôdu
5. Odpowiadaj zawsze w jƒôzyku polskim
6. Format odpowiedzi:
   - Kr√≥tkie wprowadzenie (1-2 zdania)
   - Kluczowe punkty/fakty (bullet points)
   - Przyk≈Çady kodu je≈õli to stosowne
   - ≈πr√≥d≈Ça (linki)

PRZYK≈ÅAD DOBREJ ODPOWIEDZI:
"Znalaz≈Çem informacje o obs≈Çudze kolizji w PyGame:

Kluczowe punkty:
‚Ä¢ PyGame u≈ºywa pygame.Rect.colliderect() do detekcji kolizji prostokƒÖt√≥w
‚Ä¢ Dla precyzyjnych kolizji mo≈ºna u≈ºyƒá pygame.sprite.collide_mask()
‚Ä¢ Grupy sprite'√≥w majƒÖ wbudowane metody kolizji

Przyk≈Çad kodu:
```python
# Podstawowa kolizja
if player.rect.colliderect(enemy.rect):
    handle_collision()
```

≈πr√≥d≈Ça:
- pygame.org/docs/ref/rect.html
- realpython.com/pygame-tutorial

[Zapisa≈Çem tƒô wiedzƒô w pamiƒôci pod kategoriƒÖ 'pygame_collision']"

PAMIƒòTAJ: Jeste≈õ BADACZEM, nie programistƒÖ. Dostarczasz wiedzƒô, nie piszesz finalnego kodu."""

    def __init__(self, kernel: Kernel):
        """
        Inicjalizacja ResearcherAgent.

        Args:
            kernel: Skonfigurowane jƒÖdro Semantic Kernel
        """
        super().__init__(kernel)

        # W testach nie chcemy rejestrowaƒá ciƒô≈ºkich plugin√≥w (GitHub/HF)
        self._testing_mode = bool(os.getenv("PYTEST_CURRENT_TEST"))

        # Zarejestruj WebSearchSkill
        self.web_skill = WebSearchSkill()
        self.kernel.add_plugin(self.web_skill, plugin_name="WebSearchSkill")

        if not self._testing_mode:
            # Zarejestruj GitHubSkill
            github_skill = GitHubSkill()
            self.kernel.add_plugin(github_skill, plugin_name="GitHubSkill")

            # Zarejestruj HuggingFaceSkill
            hf_skill = HuggingFaceSkill()
            self.kernel.add_plugin(hf_skill, plugin_name="HuggingFaceSkill")

        # Zarejestruj MemorySkill
        memory_skill = MemorySkill()
        self.kernel.add_plugin(memory_skill, plugin_name="MemorySkill")

        # Tracking ≈∫r√≥d≈Ça danych (dla UI badge)
        self._last_search_source = "duckduckgo"  # domy≈õlnie DuckDuckGo

        if self._testing_mode:
            logger.info(
                "ResearcherAgent zainicjalizowany w trybie testowym (WebSearch + Memory)"
            )
        else:
            logger.info(
                "ResearcherAgent zainicjalizowany z WebSearchSkill, GitHubSkill, HuggingFaceSkill i MemorySkill"
            )

    async def process(self, input_text: str) -> str:
        """
        Przetwarza pytanie badawcze i syntetyzuje wiedzƒô.

        Args:
            input_text: Pytanie lub temat do zbadania

        Returns:
            Podsumowanie znalezionej wiedzy z przyk≈Çadami
        """
        logger.info(f"ResearcherAgent przetwarza zapytanie: {input_text[:100]}...")

        auto_summary = await self._search_scrape_and_summarize(input_text)
        if auto_summary:
            logger.info("ResearcherAgent: u≈ºyto ≈õcie≈ºki search->scrape->summary")
            return auto_summary

        # Przygotuj historiƒô rozmowy
        chat_history = ChatHistory()
        chat_history.add_message(
            ChatMessageContent(role=AuthorRole.SYSTEM, content=self.SYSTEM_PROMPT)
        )
        chat_history.add_message(
            ChatMessageContent(role=AuthorRole.USER, content=input_text)
        )

        try:
            # Pobierz serwis chat completion
            chat_service = self.kernel.get_service()

            # W≈ÇƒÖcz automatyczne wywo≈Çywanie funkcji
            settings = OpenAIChatPromptExecutionSettings(
                function_choice_behavior=FunctionChoiceBehavior.Auto(),
                max_tokens=2000,  # Ogranicz d≈Çugo≈õƒá odpowiedzi
            )

            # Wywo≈Çaj model z mo≈ºliwo≈õciƒÖ auto-wywo≈Çania funkcji
            response = await self._invoke_chat_with_fallbacks(
                chat_service=chat_service,
                chat_history=chat_history,
                settings=settings,
                enable_functions=True,
            )

            result = str(response).strip()

            # Sprawd≈∫ czy odpowied≈∫ zawiera metadane Google Grounding
            response_metadata = {}
            if hasattr(response, "metadata"):
                response_metadata = response.metadata or {}

            # Dodaj ≈∫r√≥d≈Ça je≈õli sƒÖ dostƒôpne
            sources_section = format_grounding_sources(response_metadata)
            if sources_section:
                result += sources_section
                self._last_search_source = "google_grounding"
                logger.info("Dodano ≈∫r√≥d≈Ça z Google Grounding do odpowiedzi")
            else:
                # Je≈õli nie ma ≈∫r√≥de≈Ç z Grounding, oznacz ≈ºe u≈ºyto DuckDuckGo
                self._last_search_source = "duckduckgo"

            logger.info(f"ResearcherAgent wygenerowa≈Ç odpowied≈∫ ({len(result)} znak√≥w)")
            return result

        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas przetwarzania przez ResearcherAgent: {e}")
            return f"WystƒÖpi≈Ç b≈ÇƒÖd podczas badania: {str(e)}. Proszƒô spr√≥bowaƒá ponownie lub sformu≈Çowaƒá pytanie inaczej."

    def get_last_search_source(self) -> str:
        """
        Zwraca ≈∫r√≥d≈Ço ostatniego wyszukiwania (dla UI badge).

        Returns:
            'google_grounding' lub 'duckduckgo'
        """
        return self._last_search_source

    async def _search_scrape_and_summarize(self, query: str) -> str | None:
        if not query or not query.strip():
            return None

        search_output = self.web_skill.search(query, max_results=3)
        urls = self._extract_urls(search_output)
        if not urls:
            return None

        scraped: List[Tuple[str, str]] = []
        for url in urls[:2]:
            content = self.web_skill.scrape_text(url)
            if content:
                scraped.append((url, content))

        if not scraped:
            return None

        summary = await self._summarize_sources(query, scraped)
        sources_block = "\n".join(f"- {url}" for url, _ in scraped)
        return f"{summary}\n\n≈πr√≥d≈Ça:\n{sources_block}"

    @staticmethod
    def _extract_urls(search_output: str) -> List[str]:
        if not search_output:
            return []
        return re.findall(r"URL:\s*(\S+)", search_output)

    async def _summarize_sources(
        self, query: str, sources: List[Tuple[str, str]]
    ) -> str:
        chat_service = self.kernel.get_service()
        trimmed_sources = []
        for url, content in sources:
            snippet = content.strip()
            if len(snippet) > 2000:
                snippet = snippet[:2000] + "\n[...obciƒôto...]"
            trimmed_sources.append((url, snippet))

        summary_prompt = "Stw√≥rz zwiƒôz≈Çe streszczenie na podstawie ≈∫r√≥de≈Ç.\n"
        summary_prompt += f"Zapytanie: {query}\n\n≈πr√≥d≈Ça:\n"
        for idx, (url, snippet) in enumerate(trimmed_sources, 1):
            summary_prompt += f"[{idx}] {url}\n{snippet}\n\n"

        chat_history = ChatHistory()
        chat_history.add_message(
            ChatMessageContent(
                role=AuthorRole.SYSTEM,
                content="Jeste≈õ badaczem. Odpowiedz kr√≥tko i rzeczowo po polsku.",
            )
        )
        chat_history.add_message(
            ChatMessageContent(role=AuthorRole.USER, content=summary_prompt)
        )

        settings = OpenAIChatPromptExecutionSettings(max_tokens=1200)
        response = await self._invoke_chat_with_fallbacks(
            chat_service=chat_service,
            chat_history=chat_history,
            settings=settings,
            enable_functions=False,
        )
        return str(response).strip()
