"""ModuÅ‚: professor - Agent Profesor (Data Scientist i Opiekun Procesu Nauki)."""

from typing import Any, Dict, List, Optional

from semantic_kernel import Kernel

from venom_core.agents.base import BaseAgent
from venom_core.utils.logger import get_logger

logger = get_logger(__name__)


class Professor(BaseAgent):
    """
    Agent Profesor - Data Scientist i Opiekun Procesu Nauki.

    Rola:
    - Decyduje kiedy uruchomiÄ‡ trening (na podstawie liczby nowych lekcji)
    - Dobiera parametry treningowe (learning rate, epochs, LoRA rank)
    - Ewaluuje nowe modele (Arena - porÃ³wnanie z poprzedniÄ… wersjÄ…)
    - Promuje lepsze modele do produkcji
    """

    # Progi decyzyjne
    MIN_LESSONS_FOR_TRAINING = 100  # Minimum lekcji do rozpoczÄ™cia treningu
    MIN_TRAINING_INTERVAL_HOURS = 24  # Minimum godzin miÄ™dzy treningami

    # DomyÅ›lne parametry treningowe
    DEFAULT_LORA_RANK = 16
    DEFAULT_LEARNING_RATE = 2e-4
    DEFAULT_NUM_EPOCHS = 3
    DEFAULT_MAX_SEQ_LENGTH = 2048
    DEFAULT_BATCH_SIZE = 4

    def __init__(
        self,
        kernel: Kernel,
        dataset_curator=None,
        gpu_habitat=None,
        lessons_store=None,
    ):
        """
        Inicjalizacja Profesora.

        Args:
            kernel: Skonfigurowane jÄ…dro Semantic Kernel
            dataset_curator: Instancja DatasetCurator
            gpu_habitat: Instancja GPUHabitat
            lessons_store: Instancja LessonsStore
        """
        super().__init__(kernel)
        self.dataset_curator = dataset_curator
        self.gpu_habitat = gpu_habitat
        self.lessons_store = lessons_store

        # Historia treningÃ³w
        self.training_history: List[Dict[str, Any]] = []

        logger.info("Agent Professor zainicjalizowany")

    async def process(self, input_text: str) -> str:
        """
        Przetwarza wejÅ›cie i zwraca wynik.

        Rozpoznaje komendy:
        - "przygotuj materiaÅ‚y do nauki" - generuje dataset
        - "rozpocznij trening" - uruchamia trening
        - "sprawdÅº postÄ™p treningu" - status treningu
        - "oceÅ„ model" - ewaluacja modelu

        Args:
            input_text: TreÅ›Ä‡ zadania

        Returns:
            Wynik przetwarzania zadania
        """
        input_lower = input_text.lower()

        try:
            if "przygotuj materiaÅ‚y" in input_lower or "dataset" in input_lower:
                return await self._generate_dataset()

            elif "rozpocznij trening" in input_lower or "train" in input_lower:
                return await self._start_training()

            elif "sprawdÅº postÄ™p" in input_lower or "status" in input_lower:
                return await self._check_training_status()

            elif "oceÅ„ model" in input_lower or "ewaluacja" in input_lower:
                return await self._evaluate_model()

            else:
                return (
                    "Jestem Profesorem - opiekujem siÄ™ procesem nauki Venoma.\n\n"
                    "MogÄ™:\n"
                    "- PrzygotowaÄ‡ materiaÅ‚y do nauki (dataset)\n"
                    "- RozpoczÄ…Ä‡ trening modelu\n"
                    "- SprawdziÄ‡ postÄ™p treningu\n"
                    "- OceniÄ‡ jakoÅ›Ä‡ nowego modelu\n\n"
                    f"Status: {self._get_learning_status()}"
                )

        except Exception as e:
            error_msg = f"âŒ BÅ‚Ä…d podczas przetwarzania: {e}"
            logger.error(error_msg)
            return error_msg

    async def _generate_dataset(self) -> str:
        """
        Generuje dataset treningowy.

        Returns:
            Raport z generacji datasetu
        """
        if not self.dataset_curator:
            return "âŒ DatasetCurator nie jest dostÄ™pny"

        try:
            logger.info("Rozpoczynam generacjÄ™ datasetu...")

            # WyczyÅ›Ä‡ poprzednie przykÅ‚ady
            self.dataset_curator.clear()

            # Zbierz dane z rÃ³Å¼nych ÅºrÃ³deÅ‚
            lessons_count = self.dataset_curator.collect_from_lessons(limit=200)
            git_count = self.dataset_curator.collect_from_git_history(max_commits=100)

            # Filtruj niskÄ… jakoÅ›Ä‡
            removed = self.dataset_curator.filter_low_quality()

            # Zapisz dataset
            dataset_path = self.dataset_curator.save_dataset(format="alpaca")

            # Statystyki
            stats = self.dataset_curator.get_statistics()

            report = (
                "âœ… Dataset wygenerowany pomyÅ›lnie!\n\n"
                f"ðŸ“Š Statystyki:\n"
                f"- ÅÄ…czna liczba przykÅ‚adÃ³w: {stats['total_examples']}\n"
                f"- Z LessonsStore: {lessons_count}\n"
                f"- Z Git History: {git_count}\n"
                f"- UsuniÄ™to (niska jakoÅ›Ä‡): {removed}\n\n"
                f"- Åšrednia dÅ‚ugoÅ›Ä‡ input: {stats['avg_input_length']} znakÃ³w\n"
                f"- Åšrednia dÅ‚ugoÅ›Ä‡ output: {stats['avg_output_length']} znakÃ³w\n\n"
                f"ðŸ“ Lokalizacja: {dataset_path}\n\n"
            )

            if stats["total_examples"] >= 50:
                report += "âœ… Dataset speÅ‚nia minimum (50 przykÅ‚adÃ³w) i jest gotowy do treningu!"
            else:
                report += (
                    f"âš ï¸ Dataset ma tylko {stats['total_examples']} przykÅ‚adÃ³w. "
                    f"Potrzeba minimum 50 do treningu."
                )

            return report

        except Exception as e:
            error_msg = f"âŒ BÅ‚Ä…d podczas generacji datasetu: {e}"
            logger.error(error_msg)
            return error_msg

    async def _start_training(self, dataset_path: Optional[str] = None) -> str:
        """
        Rozpoczyna trening modelu.

        Args:
            dataset_path: Opcjonalna Å›cieÅ¼ka do datasetu (jeÅ›li None, uÅ¼ywa ostatniego)

        Returns:
            Raport z rozpoczÄ™cia treningu
        """
        if not self.gpu_habitat:
            return "âŒ GPUHabitat nie jest dostÄ™pny"

        try:
            # JeÅ›li nie podano Å›cieÅ¼ki, znajdÅº ostatni dataset
            if not dataset_path:
                from pathlib import Path

                training_dir = Path("./data/training")
                if not training_dir.exists():
                    return "âŒ Brak datasetu. UÅ¼yj 'przygotuj materiaÅ‚y do nauki' najpierw."

                datasets = sorted(training_dir.glob("dataset_*.jsonl"))
                if not datasets:
                    return "âŒ Brak datasetu. UÅ¼yj 'przygotuj materiaÅ‚y do nauki' najpierw."

                dataset_path = str(datasets[-1])

            # SprawdÅº czy powinniÅ›my trenowaÄ‡
            decision = self.should_start_training()
            if not decision["should_train"]:
                return f"âš ï¸ Nie speÅ‚niono kryteriÃ³w dla treningu:\n{decision['reason']}"

            # Dobierz parametry
            params = self._select_training_parameters()

            logger.info(f"Rozpoczynam trening z parametrami: {params}")

            # Uruchom trening
            from pathlib import Path

            output_dir = (
                Path("./data/models") / f"training_{len(self.training_history)}"
            )

            job_info = self.gpu_habitat.run_training_job(
                dataset_path=dataset_path,
                base_model=params["base_model"],
                output_dir=str(output_dir),
                lora_rank=params["lora_rank"],
                learning_rate=params["learning_rate"],
                num_epochs=params["num_epochs"],
                max_seq_length=params["max_seq_length"],
                batch_size=params["batch_size"],
            )

            # Zapisz w historii
            from datetime import datetime

            self.training_history.append(
                {
                    "job_name": job_info["job_name"],
                    "dataset_path": dataset_path,
                    "params": params,
                    "status": "running",
                    "started_at": datetime.now().isoformat(),
                }
            )

            report = (
                "âœ… Trening rozpoczÄ™ty!\n\n"
                f"ðŸ‹ï¸ Job: {job_info['job_name']}\n"
                f"ðŸ“¦ Kontener: {job_info['container_id'][:12]}\n"
                f"ðŸ“Š Dataset: {Path(dataset_path).name}\n\n"
                f"âš™ï¸ Parametry:\n"
                f"- Model bazowy: {params['base_model']}\n"
                f"- LoRA rank: {params['lora_rank']}\n"
                f"- Learning rate: {params['learning_rate']}\n"
                f"- Epoki: {params['num_epochs']}\n"
                f"- Batch size: {params['batch_size']}\n\n"
                f"ðŸ“ Adapter zostanie zapisany w: {job_info['adapter_path']}\n\n"
                "UÅ¼yj 'sprawdÅº postÄ™p treningu' aby monitorowaÄ‡."
            )

            return report

        except Exception as e:
            error_msg = f"âŒ BÅ‚Ä…d podczas rozpoczynania treningu: {e}"
            logger.error(error_msg)
            return error_msg

    async def _check_training_status(self) -> str:
        """
        Sprawdza status aktualnego treningu.

        Returns:
            Raport ze statusem
        """
        if not self.training_history:
            return "â„¹ï¸ Brak aktywnych treningÃ³w"

        try:
            # Pobierz ostatni trening
            last_training = self.training_history[-1]
            job_name = last_training["job_name"]

            # SprawdÅº status
            status_info = self.gpu_habitat.get_training_status(job_name)

            # Aktualizuj status w historii
            last_training["status"] = status_info["status"]

            report = (
                f"ðŸ“Š Status treningu: {job_name}\n\n"
                f"Status: {status_info['status'].upper()}\n"
                f"Kontener: {status_info['container_id'][:12]}\n\n"
                f"ðŸ“œ Ostatnie logi:\n"
                f"```\n{status_info['logs'][-500:]}\n```\n"
            )

            if status_info["status"] == "completed":
                report += "\nâœ… Trening zakoÅ„czony! MoÅ¼esz oceniÄ‡ nowy model."
            elif status_info["status"] == "failed":
                report += "\nâŒ Trening zakoÅ„czyÅ‚ siÄ™ bÅ‚Ä™dem. SprawdÅº logi."

            return report

        except Exception as e:
            error_msg = f"âŒ BÅ‚Ä…d podczas sprawdzania statusu: {e}"
            logger.error(error_msg)
            return error_msg

    async def _evaluate_model(self) -> str:
        """
        Ewaluuje nowy model (Arena - porÃ³wnanie z poprzedniÄ… wersjÄ…).

        Returns:
            Raport z ewaluacji
        """
        # TODO: Implementacja Arena - zestawu testÃ³w porÃ³wnawczych
        # Mockowy raport na razie
        report = (
            "ðŸŸï¸ ARENA - Ewaluacja Modelu\n\n"
            "âš ï¸ FunkcjonalnoÅ›Ä‡ w rozwoju\n\n"
            "Plan:\n"
            "1. Uruchomienie zestawu testÃ³w (10 pytaÅ„ kodowania)\n"
            "2. PorÃ³wnanie odpowiedzi: Stary Model vs Nowy Model\n"
            "3. Ocena jakoÅ›ci (human eval lub automated metrics)\n"
            "4. Decyzja o promocji\n\n"
            "Mock Result:\n"
            "- Stary Model: 7/10 poprawnych\n"
            "- Nowy Model: 8/10 poprawnych\n"
            "- Improvement: +14%\n\n"
            "âœ… REKOMENDACJA: Promuj nowy model do produkcji"
        )

        return report

    def should_start_training(self) -> Dict[str, Any]:
        """
        Decyduje czy powinno siÄ™ rozpoczÄ…Ä‡ trening.

        Returns:
            SÅ‚ownik z decyzjÄ…:
            - should_train: bool
            - reason: str (wyjaÅ›nienie)
        """
        if not self.lessons_store:
            return {
                "should_train": False,
                "reason": "LessonsStore nie jest dostÄ™pny",
            }

        # SprawdÅº liczbÄ™ nowych lekcji
        stats = self.lessons_store.get_statistics()
        total_lessons = stats.get("total_lessons", 0)

        if total_lessons < self.MIN_LESSONS_FOR_TRAINING:
            return {
                "should_train": False,
                "reason": (
                    f"Za maÅ‚o lekcji ({total_lessons}). "
                    f"Potrzeba minimum {self.MIN_LESSONS_FOR_TRAINING}."
                ),
            }

        # TODO: SprawdÅº interwaÅ‚ od ostatniego treningu
        # (wymaga zapisywania timestampÃ³w w training_history)

        return {
            "should_train": True,
            "reason": f"Zebrano {total_lessons} lekcji. Gotowy do treningu!",
        }

    def _select_training_parameters(self) -> Dict[str, Any]:
        """
        Dobiera optymalne parametry treningowe.

        Returns:
            SÅ‚ownik z parametrami treningu
        """
        # TODO: Inteligentny dobÃ³r parametrÃ³w na podstawie:
        # - Rozmiaru datasetu
        # - DostÄ™pnej VRAM
        # - WczeÅ›niejszych wynikÃ³w

        # Na razie zwracamy domyÅ›lne parametry
        return {
            "base_model": "unsloth/Phi-3-mini-4k-instruct",
            "lora_rank": self.DEFAULT_LORA_RANK,
            "learning_rate": self.DEFAULT_LEARNING_RATE,
            "num_epochs": self.DEFAULT_NUM_EPOCHS,
            "max_seq_length": self.DEFAULT_MAX_SEQ_LENGTH,
            "batch_size": self.DEFAULT_BATCH_SIZE,
        }

    def _get_learning_status(self) -> str:
        """
        Zwraca aktualny status systemu uczenia.

        Returns:
            Tekstowy status
        """
        if not self.lessons_store:
            return "LessonsStore niedostÄ™pny"

        stats = self.lessons_store.get_statistics()
        total_lessons = stats.get("total_lessons", 0)

        trainings_count = len(self.training_history)

        return (
            f"{total_lessons} lekcji zebrano, "
            f"{trainings_count} treningÃ³w przeprowadzono"
        )
