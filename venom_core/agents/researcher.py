"""Modu≈Ç: researcher - agent badawczy, synteza wiedzy z Internetu."""

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.function_choice_behavior import (
    FunctionChoiceBehavior,
)
from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings
from semantic_kernel.contents import ChatHistory
from semantic_kernel.contents.chat_message_content import ChatMessageContent
from semantic_kernel.contents.utils.author_role import AuthorRole

from venom_core.agents.base import BaseAgent
from venom_core.execution.skills.github_skill import GitHubSkill
from venom_core.execution.skills.huggingface_skill import HuggingFaceSkill
from venom_core.execution.skills.web_skill import WebSearchSkill
from venom_core.memory.memory_skill import MemorySkill
from venom_core.utils.logger import get_logger

logger = get_logger(__name__)


def format_grounding_sources(response_metadata: dict) -> str:
    """
    Formatuje ≈∫r√≥d≈Ça z Google Grounding do czytelnej formy.
    
    Args:
        response_metadata: Metadane odpowiedzi z API (grounding_metadata, web_search_queries)
    
    Returns:
        Sformatowana sekcja ze ≈∫r√≥d≈Çami lub pusty string je≈õli brak
    """
    if not response_metadata:
        return ""
    
    sources = []
    
    # Sprawd≈∫ grounding_metadata
    grounding_metadata = response_metadata.get("grounding_metadata", {})
    if grounding_metadata and grounding_metadata.get("grounding_chunks"):
        chunks = grounding_metadata.get("grounding_chunks", [])
        for idx, chunk in enumerate(chunks, 1):
            title = chunk.get("title", "Brak tytu≈Çu")
            uri = chunk.get("uri", "")
            if uri:
                sources.append(f"[{idx}] {title} - {uri}")
    
    # Sprawd≈∫ web_search_queries (alternatywne ≈∫r√≥d≈Ço metadanych)
    web_queries = response_metadata.get("web_search_queries", [])
    if web_queries and not sources:
        for idx, query in enumerate(web_queries, 1):
            sources.append(f"[{idx}] Zapytanie: {query}")
    
    if sources:
        sources_section = "\n\n---\nüìö ≈πr√≥d≈Ça (Google Grounding):\n" + "\n".join(sources)
        return sources_section
    
    return ""


class ResearcherAgent(BaseAgent):
    """Agent specjalizujƒÖcy siƒô w badaniu i syntezie wiedzy z Internetu."""

    SYSTEM_PROMPT = """Jeste≈õ ekspertem badawczym (Researcher). Twoim zadaniem jest znajdowanie i synteza wiedzy z Internetu.

TWOJE NARZƒòDZIA:
- search: Wyszukaj informacje w Internecie (DuckDuckGo)
- scrape_text: Pobierz i oczy≈õƒá tre≈õƒá konkretnej strony WWW
- search_and_scrape: Wyszukaj i automatycznie pobierz tre≈õƒá z najlepszych wynik√≥w
- search_repos: Wyszukaj repozytoria na GitHub (biblioteki, narzƒôdzia)
- get_readme: Pobierz README z repozytorium GitHub
- get_trending: Znajd≈∫ popularne projekty na GitHub
- search_models: Wyszukaj modele AI na Hugging Face
- get_model_card: Pobierz szczeg√≥≈Çy modelu z Hugging Face
- search_datasets: Wyszukaj zbiory danych na Hugging Face
- memorize: Zapisz wa≈ºne informacje do pamiƒôci d≈Çugoterminowej
- recall: Przywo≈Çaj informacje z pamiƒôci

ZASADY:
1. NIE PISZESZ KODU - Twoja rola to dostarczanie FAKT√ìW i WIEDZY
2. Gdy otrzymasz pytanie:
   - Najpierw sprawd≈∫ pamiƒôƒá (recall) czy nie masz ju≈º tej informacji
   - Je≈õli nie ma w pamiƒôci, wyszukaj w Internecie (search lub search_and_scrape)
   - Przeanalizuj wyniki z 2-3 najlepszych ≈∫r√≥de≈Ç
   - Stw√≥rz ZWIƒòZ≈ÅE PODSUMOWANIE TECHNICZNE z przyk≈Çadami kodu je≈õli to stosowne
3. Po zebraniu wiedzy:
   - Zapisz wa≈ºne informacje do pamiƒôci (memorize) na przysz≈Ço≈õƒá
   - Kategoryzuj wiedzƒô odpowiednio (documentation, code_example, best_practice, etc.)
4. Je≈õli strona nie dzia≈Ça (404, timeout):
   - Spr√≥buj innego wyniku z wyszukiwania
   - NIE PRZERYWAJ ca≈Çego procesu z powodu jednego b≈Çƒôdu
5. Odpowiadaj zawsze w jƒôzyku polskim
6. Format odpowiedzi:
   - Kr√≥tkie wprowadzenie (1-2 zdania)
   - Kluczowe punkty/fakty (bullet points)
   - Przyk≈Çady kodu je≈õli to stosowne
   - ≈πr√≥d≈Ça (linki)

PRZYK≈ÅAD DOBREJ ODPOWIEDZI:
"Znalaz≈Çem informacje o obs≈Çudze kolizji w PyGame:

Kluczowe punkty:
‚Ä¢ PyGame u≈ºywa pygame.Rect.colliderect() do detekcji kolizji prostokƒÖt√≥w
‚Ä¢ Dla precyzyjnych kolizji mo≈ºna u≈ºyƒá pygame.sprite.collide_mask()
‚Ä¢ Grupy sprite'√≥w majƒÖ wbudowane metody kolizji

Przyk≈Çad kodu:
```python
# Podstawowa kolizja
if player.rect.colliderect(enemy.rect):
    handle_collision()
```

≈πr√≥d≈Ça:
- pygame.org/docs/ref/rect.html
- realpython.com/pygame-tutorial

[Zapisa≈Çem tƒô wiedzƒô w pamiƒôci pod kategoriƒÖ 'pygame_collision']"

PAMIƒòTAJ: Jeste≈õ BADACZEM, nie programistƒÖ. Dostarczasz wiedzƒô, nie piszesz finalnego kodu."""

    def __init__(self, kernel: Kernel):
        """
        Inicjalizacja ResearcherAgent.

        Args:
            kernel: Skonfigurowane jƒÖdro Semantic Kernel
        """
        super().__init__(kernel)

        # Zarejestruj WebSearchSkill
        web_skill = WebSearchSkill()
        self.kernel.add_plugin(web_skill, plugin_name="WebSearchSkill")

        # Zarejestruj GitHubSkill
        github_skill = GitHubSkill()
        self.kernel.add_plugin(github_skill, plugin_name="GitHubSkill")

        # Zarejestruj HuggingFaceSkill
        hf_skill = HuggingFaceSkill()
        self.kernel.add_plugin(hf_skill, plugin_name="HuggingFaceSkill")

        # Zarejestruj MemorySkill
        memory_skill = MemorySkill()
        self.kernel.add_plugin(memory_skill, plugin_name="MemorySkill")
        
        # Tracking ≈∫r√≥d≈Ça danych (dla UI badge)
        self._last_search_source = "duckduckgo"  # domy≈õlnie DuckDuckGo

        logger.info(
            "ResearcherAgent zainicjalizowany z WebSearchSkill, GitHubSkill, HuggingFaceSkill i MemorySkill"
        )

    async def process(self, input_text: str) -> str:
        """
        Przetwarza pytanie badawcze i syntetyzuje wiedzƒô.

        Args:
            input_text: Pytanie lub temat do zbadania

        Returns:
            Podsumowanie znalezionej wiedzy z przyk≈Çadami
        """
        logger.info(f"ResearcherAgent przetwarza zapytanie: {input_text[:100]}...")

        # Przygotuj historiƒô rozmowy
        chat_history = ChatHistory()
        chat_history.add_message(
            ChatMessageContent(role=AuthorRole.SYSTEM, content=self.SYSTEM_PROMPT)
        )
        chat_history.add_message(
            ChatMessageContent(role=AuthorRole.USER, content=input_text)
        )

        try:
            # Pobierz serwis chat completion
            chat_service = self.kernel.get_service()

            # W≈ÇƒÖcz automatyczne wywo≈Çywanie funkcji
            settings = OpenAIChatPromptExecutionSettings(
                function_choice_behavior=FunctionChoiceBehavior.Auto(),
                max_tokens=2000,  # Ogranicz d≈Çugo≈õƒá odpowiedzi
            )

            # Wywo≈Çaj model z mo≈ºliwo≈õciƒÖ auto-wywo≈Çania funkcji
            response = await chat_service.get_chat_message_content(
                chat_history=chat_history, settings=settings
            )

            result = str(response).strip()
            
            # Sprawd≈∫ czy odpowied≈∫ zawiera metadane Google Grounding
            response_metadata = {}
            if hasattr(response, 'metadata'):
                response_metadata = response.metadata or {}
            
            # Dodaj ≈∫r√≥d≈Ça je≈õli sƒÖ dostƒôpne
            sources_section = format_grounding_sources(response_metadata)
            if sources_section:
                result += sources_section
                self._last_search_source = "google_grounding"
                logger.info("Dodano ≈∫r√≥d≈Ça z Google Grounding do odpowiedzi")
            else:
                # Je≈õli nie ma ≈∫r√≥de≈Ç z Grounding, oznacz ≈ºe u≈ºyto DuckDuckGo
                self._last_search_source = "duckduckgo"
            
            logger.info(f"ResearcherAgent wygenerowa≈Ç odpowied≈∫ ({len(result)} znak√≥w)")
            return result

        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas przetwarzania przez ResearcherAgent: {e}")
            return f"WystƒÖpi≈Ç b≈ÇƒÖd podczas badania: {str(e)}. Proszƒô spr√≥bowaƒá ponownie lub sformu≈Çowaƒá pytanie inaczej."
    
    def get_last_search_source(self) -> str:
        """
        Zwraca ≈∫r√≥d≈Ço ostatniego wyszukiwania (dla UI badge).
        
        Returns:
            'google_grounding' lub 'duckduckgo'
        """
        return self._last_search_source
