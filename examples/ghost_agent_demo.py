"""
Przyk≈Çad u≈ºycia Ghost Agent - Visual GUI Automation.

Ten skrypt demonstruje podstawowe mo≈ºliwo≈õci Ghost Agent:
1. Otwieranie aplikacji (Notatnik)
2. Wpisywanie tekstu
3. Interakcja z GUI
"""

import asyncio
import sys
from pathlib import Path

# Dodaj venom_core do ≈õcie≈ºki
sys.path.insert(0, str(Path(__file__).parent.parent))

from venom_core.agents.ghost_agent import GhostAgent
from venom_core.config import SETTINGS
from venom_core.execution.kernel_builder import KernelBuilder


async def demo_notepad():
    """Demo: Otw√≥rz notatnik i napisz tekst."""
    print("=" * 60)
    print("DEMO 1: Otw√≥rz Notatnik i napisz tekst")
    print("=" * 60)

    # Zbuduj kernel
    kernel = KernelBuilder().build()

    # Utw√≥rz Ghost Agent
    ghost = GhostAgent(
        kernel=kernel,
        max_steps=20,
        step_delay=1.0,  # 1 sekunda miƒôdzy krokami
        verification_enabled=False,  # Dla demo wy≈ÇƒÖczamy weryfikacjƒô
    )

    # Wykonaj zadanie
    result = await ghost.process("Otw√≥rz notatnik i napisz 'Hello from Ghost Agent!'")

    print("\n" + result)
    print("\n‚úÖ Demo zako≈Ñczone")


async def demo_input_skill():
    """Demo: Bezpo≈õrednie u≈ºycie InputSkill."""
    print("\n" + "=" * 60)
    print("DEMO 2: Bezpo≈õrednie u≈ºycie InputSkill")
    print("=" * 60)

    from venom_core.execution.skills.input_skill import InputSkill

    input_skill = InputSkill(safety_delay=0.5)

    # Pobierz pozycjƒô myszy
    print("\n1. Pobieranie pozycji myszy...")
    position = await input_skill.get_mouse_position()
    print(f"   {position}")

    # Pobierz rozmiar ekranu
    print("\n2. Pobieranie rozmiaru ekranu...")
    width, height = input_skill.get_screen_size()
    print(f"   Rozmiar ekranu: {width}x{height}")

    # Zr√≥b screenshot
    print("\n3. Robienie zrzutu ekranu...")
    screenshot_result = await input_skill.take_screenshot()
    print(f"   {screenshot_result}")

    print("\n‚úÖ Demo zako≈Ñczone")


async def demo_vision_grounding():
    """Demo: Vision Grounding (wymaga OpenAI API key)."""
    print("\n" + "=" * 60)
    print("DEMO 3: Vision Grounding")
    print("=" * 60)

    if not SETTINGS.OPENAI_API_KEY:
        print("‚ö†Ô∏è  UWAGA: Brak OPENAI_API_KEY w konfiguracji")
        print("   Vision Grounding bƒôdzie u≈ºywaƒá fallback (OCR)")
        print("   Ustaw OPENAI_API_KEY w .env aby uzyskaƒá lepsze rezultaty")

    from PIL import ImageGrab

    from venom_core.perception.vision_grounding import VisionGrounding

    vision = VisionGrounding()

    print("\n1. Robienie zrzutu ekranu...")
    screenshot = ImageGrab.grab()
    print(f"   Screenshot: {screenshot.size[0]}x{screenshot.size[1]} pikseli")

    print(
        "\n2. Szukanie elementu 'przycisku Start' (to przyk≈Çad - mo≈ºe nie znale≈∫ƒá)..."
    )
    coords = await vision.locate_element(screenshot, description="przycisk Start")

    if coords:
        x, y = coords
        print(f"   ‚úÖ Element znaleziony: ({x}, {y})")
    else:
        print("   ‚ÑπÔ∏è  Element nie znaleziony (to normalne w demo)")

    print("\n‚úÖ Demo zako≈Ñczone")


async def main():
    """G≈Ç√≥wna funkcja demo."""
    print("\n" + "üé≠" * 30)
    print("   GHOST AGENT - Visual GUI Automation Demo")
    print("üé≠" * 30)

    print("\n‚ö†Ô∏è  WA≈ªNE OSTRZE≈ªENIA:")
    print("1. Ghost Agent bƒôdzie kontrolowaƒá mysz i klawiaturƒô")
    print("2. Przesu≈Ñ mysz do rogu (0,0) aby NATYCHMIAST przerwaƒá")
    print("3. Upewnij siƒô ≈ºe nie masz otwartych wa≈ºnych aplikacji")
    print("4. Demo najlepiej dzia≈Ça na Windows")

    input("\nNaci≈õnij Enter aby kontynuowaƒá (lub Ctrl+C aby anulowaƒá)...")

    try:
        # Demo 1: Notatnik (tylko na Windows/Linux z GUI)
        import platform

        if platform.system() in ["Windows", "Linux"]:
            await demo_notepad()
        else:
            print(f"\n‚ö†Ô∏è  Demo 1 pomijane (System: {platform.system()})")

        # Demo 2: InputSkill (dzia≈Ça wszƒôdzie)
        await demo_input_skill()

        # Demo 3: Vision Grounding (wymaga GUI)
        if platform.system() in ["Windows", "Linux"]:
            await demo_vision_grounding()
        else:
            print(f"\n‚ö†Ô∏è  Demo 3 pomijane (System: {platform.system()})")

    except KeyboardInterrupt:
        print("\n\nüõë Demo przerwane przez u≈ºytkownika")
    except Exception as e:
        print(f"\n\n‚ùå B≈ÇƒÖd: {e}")
        import traceback

        traceback.print_exc()

    print("\n" + "=" * 60)
    print("Dziƒôkujemy za wypr√≥bowanie Ghost Agent!")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
