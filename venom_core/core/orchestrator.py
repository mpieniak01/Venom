"""ModuÅ‚: orchestrator - orkiestracja zadaÅ„ w tle."""

import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Optional
from uuid import UUID

from venom_core.agents.base import reset_llm_stream_callback, set_llm_stream_callback
from venom_core.config import SETTINGS
from venom_core.core import metrics as metrics_module
from venom_core.core.dispatcher import TaskDispatcher
from venom_core.core.flow_router import FlowRouter
from venom_core.core.flows.campaign import CampaignFlow
from venom_core.core.flows.code_review import (
    MAX_REPAIR_ATTEMPTS as CODE_REVIEW_MAX_REPAIR_ATTEMPTS,
)
from venom_core.core.flows.code_review import CodeReviewLoop
from venom_core.core.flows.council import (
    COUNCIL_COLLABORATION_KEYWORDS as COUNCIL_KEYWORDS,
)
from venom_core.core.flows.council import COUNCIL_TASK_THRESHOLD as COUNCIL_THRESHOLD
from venom_core.core.flows.council import ENABLE_COUNCIL_MODE as COUNCIL_ENABLE_FLAG
from venom_core.core.flows.council import CouncilFlow
from venom_core.core.flows.forge import ForgeFlow
from venom_core.core.flows.healing import HealingFlow
from venom_core.core.flows.issue_handler import IssueHandlerFlow
from venom_core.core.hidden_prompts import build_hidden_prompts_context
from venom_core.core.intent_manager import IntentManager
from venom_core.core.lessons_manager import LessonsManager
from venom_core.core.models import TaskRequest, TaskResponse, TaskStatus
from venom_core.core.queue_manager import QueueManager
from venom_core.core.state_manager import StateManager
from venom_core.core.streaming_handler import StreamingHandler
from venom_core.core.tracer import RequestTracer, TraceStatus
from venom_core.execution.kernel_builder import KernelBuilder
from venom_core.perception.eyes import Eyes
from venom_core.utils.llm_runtime import compute_llm_config_hash, get_active_llm_runtime
from venom_core.utils.logger import get_logger

logger = get_logger(__name__)

# Ustawienia dla pÄ™tli meta-uczenia
MAX_LESSONS_IN_CONTEXT = 3  # Maksymalna liczba lekcji doÅ‚Ä…czanych do promptu
LEARNING_LOG_PATH = Path("./data/learning/requests.jsonl")
MAX_LEARNING_SNIPPET = 1200
MAX_HIDDEN_PROMPTS_IN_CONTEXT = 2
# Alias dla kompatybilnoÅ›ci z testami i innymi moduÅ‚ami
MAX_REPAIR_ATTEMPTS = CODE_REVIEW_MAX_REPAIR_ATTEMPTS
COUNCIL_COLLABORATION_KEYWORDS = COUNCIL_KEYWORDS
COUNCIL_TASK_THRESHOLD = COUNCIL_THRESHOLD
ENABLE_COUNCIL_MODE = COUNCIL_ENABLE_FLAG


class Orchestrator:
    """Orkiestrator zadaÅ„ - zarzÄ…dzanie wykonywaniem zadaÅ„ w tle."""

    def __init__(
        self,
        state_manager: StateManager,
        intent_manager: IntentManager = None,
        task_dispatcher: TaskDispatcher = None,
        event_broadcaster=None,
        lessons_store=None,
        node_manager=None,
        request_tracer: RequestTracer = None,
    ):
        """
        Inicjalizacja Orchestrator.

        Args:
            state_manager: MenedÅ¼er stanu zadaÅ„
            intent_manager: Opcjonalny menedÅ¼er klasyfikacji intencji (jeÅ›li None, zostanie utworzony)
            task_dispatcher: Opcjonalny dispatcher zadaÅ„ (jeÅ›li None, zostanie utworzony)
            event_broadcaster: Opcjonalny broadcaster zdarzeÅ„ do WebSocket
            lessons_store: Opcjonalny magazyn lekcji (dla meta-uczenia)
            node_manager: Opcjonalny menedÅ¼er wÄ™zÅ‚Ã³w (dla distributed execution)
            request_tracer: Opcjonalny tracer do Å›ledzenia przepÅ‚ywu zadaÅ„
        """
        self.state_manager = state_manager
        self.intent_manager = intent_manager or IntentManager()
        self.event_broadcaster = event_broadcaster
        self.lessons_store = lessons_store  # Magazyn lekcji dla meta-uczenia
        self.node_manager = node_manager  # MenedÅ¼er wÄ™zÅ‚Ã³w dla distributed execution
        self.request_tracer = request_tracer  # Tracer do Å›ledzenia przepÅ‚ywu

        # Inicjalizuj dispatcher jeÅ›li nie zostaÅ‚ przekazany
        if task_dispatcher is None:
            kernel_builder = KernelBuilder()
            kernel = kernel_builder.build_kernel()
            task_dispatcher = TaskDispatcher(
                kernel, event_broadcaster=event_broadcaster, node_manager=node_manager
            )

        self.task_dispatcher = task_dispatcher
        self._kernel_config_hash = get_active_llm_runtime().config_hash

        # Inicjalizuj Eyes dla obsÅ‚ugi obrazÃ³w
        self.eyes = Eyes()

        # Inicjalizuj nowe komponenty (refactored)
        self.streaming_handler = StreamingHandler(state_manager=state_manager)
        self.lessons_manager = LessonsManager(
            state_manager=state_manager,
            lessons_store=lessons_store,
            event_broadcaster=event_broadcaster,
        )
        self.flow_router = FlowRouter()  # Lazy initialized z council_flow

        # Inicjalizuj flows (delegowane logiki biznesowe)
        self._code_review_loop = None
        self._council_flow = None
        self._council_config = None
        self._forge_flow = None
        self._campaign_flow = None
        self._healing_flow = None
        self._issue_handler_flow = None

        # Tracking ostatniej aktywnoÅ›ci dla idle mode
        self.last_activity: Optional[datetime] = None

        # Queue Manager (Dashboard v2.3) - delegacja zarzÄ…dzania kolejkÄ…
        self.queue_manager = QueueManager(
            state_manager=state_manager, event_broadcaster=event_broadcaster
        )

    def _refresh_kernel(self, runtime_info=None) -> None:
        """Odtwarza kernel i agentÃ³w po zmianie konfiguracji LLM."""
        runtime_info = runtime_info or get_active_llm_runtime()
        logger.info(
            "OdÅ›wieÅ¼am kernel po zmianie LLM (hash=%s).",
            runtime_info.config_hash,
        )
        kernel_builder = KernelBuilder()
        kernel = kernel_builder.build_kernel()
        goal_store = getattr(self.task_dispatcher, "goal_store", None)
        self.task_dispatcher = TaskDispatcher(
            kernel,
            event_broadcaster=self.event_broadcaster,
            node_manager=self.node_manager,
            goal_store=goal_store,
        )
        self._kernel_config_hash = runtime_info.config_hash
        # Resetuj flowy zaleÅ¼ne od dispatcherÃ³w, aby uÅ¼yÅ‚y nowego kernela.
        self._code_review_loop = None
        self._council_flow = None
        self._forge_flow = None
        self._campaign_flow = None
        self._healing_flow = None
        self._issue_handler_flow = None

    def _refresh_kernel_if_needed(self) -> None:
        """Sprawdza drift konfiguracji i odÅ›wieÅ¼a kernel przy zmianie."""
        runtime_info = get_active_llm_runtime()
        current_hash = runtime_info.config_hash
        if self._kernel_config_hash != current_hash:
            self._refresh_kernel(runtime_info)

    @property
    def is_paused(self) -> bool:
        """Zwraca, czy kolejka jest wstrzymana (delegacja do queue_manager)."""
        return self.queue_manager.is_paused

    @property
    def active_tasks(self) -> dict:
        """Zwraca sÅ‚ownik aktywnych zadaÅ„ (delegacja do queue_manager)."""
        return self.queue_manager.active_tasks

    async def _broadcast_event(
        self, event_type: str, message: str, agent: str = None, data: dict = None
    ):
        """
        WysyÅ‚a zdarzenie do WebSocket (jeÅ›li broadcaster jest dostÄ™pny).

        Args:
            event_type: Typ zdarzenia
            message: TreÅ›Ä‡ wiadomoÅ›ci
            agent: Opcjonalna nazwa agenta
            data: Opcjonalne dodatkowe dane
        """
        if self.event_broadcaster:
            await self.event_broadcaster.broadcast_event(
                event_type=event_type, message=message, agent=agent, data=data
            )

    async def submit_task(self, request: TaskRequest) -> TaskResponse:
        """
        Przyjmuje nowe zadanie do wykonania.

        Args:
            request: Å»Ä…danie z treÅ›ciÄ… zadania

        Returns:
            OdpowiedÅº z ID zadania i statusem
        """
        self._refresh_kernel_if_needed()
        # Zaktualizuj czas ostatniej aktywnoÅ›ci
        self.last_activity = datetime.now()

        # UtwÃ³rz zadanie przez StateManager
        task = self.state_manager.create_task(content=request.content)

        runtime_info = get_active_llm_runtime()
        runtime_context = runtime_info.to_payload()
        if request.expected_config_hash:
            runtime_context["expected_config_hash"] = request.expected_config_hash
        if request.expected_runtime_id:
            runtime_context["expected_runtime_id"] = request.expected_runtime_id
        runtime_context["status"] = "ready"
        self.state_manager.update_context(task.id, {"llm_runtime": runtime_context})

        # UtwÃ³rz trace dla zadania jeÅ›li tracer jest dostÄ™pny
        if self.request_tracer:
            self.request_tracer.create_trace(task.id, request.content)
            self.request_tracer.add_step(
                task.id,
                "User",
                "submit_request",
                status="ok",
                details="Request received",
            )
            self.request_tracer.set_llm_metadata(
                task.id, metadata=runtime_context.copy()
            )

        # Zaloguj event
        log_message = f"Zadanie uruchomione: {datetime.now().isoformat()}"
        self.state_manager.add_log(task.id, log_message)

        # Broadcast zdarzenia utworzenia zadania
        await self._broadcast_event(
            event_type="TASK_CREATED",
            message=f"Utworzono nowe zadanie: {request.content[:100]}...",
            data={"task_id": str(task.id), "content": request.content},
        )

        # Zapisz obrazy w kontekÅ›cie zadania jeÅ›li istniejÄ…
        if request.images:
            self.state_manager.add_log(
                task.id, f"Zadanie zawiera {len(request.images)} obrazÃ³w"
            )

        # SprawdÅº czy system jest w trybie pauzy
        if self.queue_manager.is_paused:
            self.state_manager.add_log(
                task.id, "â¸ï¸ System w trybie pauzy - zadanie czeka w kolejce"
            )
            await self._broadcast_event(
                event_type="TASK_QUEUED",
                message=f"Zadanie {task.id} oczekuje - system wstrzymany",
                data={"task_id": str(task.id)},
            )
            logger.info(f"Zadanie {task.id} zakolejkowane - system w pauzie")
            return TaskResponse(
                task_id=task.id,
                status=task.status,
                llm_provider=runtime_info.provider,
                llm_model=runtime_info.model_name,
                llm_endpoint=runtime_info.endpoint,
            )

        # SprawdÅº limit wspÃ³Å‚bieÅ¼noÅ›ci
        if SETTINGS.ENABLE_QUEUE_LIMITS:
            has_capacity, active_count = await self.queue_manager.check_capacity()
            if not has_capacity:
                self.state_manager.add_log(
                    task.id,
                    f"â³ OsiÄ…gniÄ™to limit wspÃ³Å‚bieÅ¼noÅ›ci ({active_count}/{SETTINGS.MAX_CONCURRENT_TASKS}) - zadanie czeka",
                )
                await self._broadcast_event(
                    event_type="TASK_QUEUED",
                    message=f"Zadanie {task.id} oczekuje - limit zadaÅ„ rÃ³wnolegÅ‚ych",
                    data={
                        "task_id": str(task.id),
                        "active": active_count,
                        "limit": SETTINGS.MAX_CONCURRENT_TASKS,
                    },
                )
                logger.info(
                    f"Zadanie {task.id} czeka - limit wspÃ³Å‚bieÅ¼noÅ›ci ({active_count}/{SETTINGS.MAX_CONCURRENT_TASKS})"
                )
                # Zadanie czeka - uruchom w tle ale bÄ™dzie oczekiwaÄ‡
                asyncio.create_task(self._run_task_with_queue(task.id, request))
                return TaskResponse(
                    task_id=task.id,
                    status=task.status,
                    llm_provider=runtime_info.provider,
                    llm_model=runtime_info.model_name,
                    llm_endpoint=runtime_info.endpoint,
                )

        # Uruchom zadanie w tle (przekaÅ¼ request zamiast tylko ID)
        asyncio.create_task(self._run_task_with_queue(task.id, request))

        logger.info(f"Zadanie {task.id} przyjÄ™te do wykonania")

        return TaskResponse(
            task_id=task.id,
            status=task.status,
            llm_provider=runtime_info.provider,
            llm_model=runtime_info.model_name,
            llm_endpoint=runtime_info.endpoint,
        )

    async def _run_task_with_queue(self, task_id: UUID, request: TaskRequest) -> None:
        """
        Wrapper dla _run_task z obsÅ‚ugÄ… kolejki i limitÃ³w wspÃ³Å‚bieÅ¼noÅ›ci.

        Args:
            task_id: ID zadania do wykonania
            request: Oryginalne Å¼Ä…danie
        """
        # Czekaj na dostÄ™pny slot jeÅ›li potrzeba
        while True:
            # SprawdÅº pauzÄ™
            if self.queue_manager.is_paused:
                # Pauza aktywna, czekaj
                await asyncio.sleep(0.5)
                continue

            # SprawdÅº limit
            has_capacity, _ = await self.queue_manager.check_capacity()
            if has_capacity:
                # UtwÃ³rz task handle
                task_handle = asyncio.current_task()
                if task_handle is None:
                    logger.error(f"Nie moÅ¼na uzyskaÄ‡ task handle dla {task_id}")
                    # Oznacz zadanie jako FAILED aby nie pozostaÅ‚o w PENDING
                    await self.state_manager.update_status(
                        task_id,
                        TaskStatus.FAILED,
                        result="BÅ‚Ä…d systemu: nie moÅ¼na uzyskaÄ‡ task handle",
                    )
                    return
                await self.queue_manager.register_task(task_id, task_handle)
                break

            # Czekaj na zwolnienie slotu
            await asyncio.sleep(0.5)

        try:
            # Wykonaj zadanie
            await self._run_task(task_id, request)
        finally:
            # UsuÅ„ z active tasks
            await self.queue_manager.unregister_task(task_id)

    async def pause_queue(self) -> dict:
        """
        Wstrzymuje przyjmowanie nowych zadaÅ„ do wykonania.

        Returns:
            Dict z wynikiem operacji
        """
        return await self.queue_manager.pause()

    async def resume_queue(self) -> dict:
        """
        Wznawia przyjmowanie zadaÅ„.

        Returns:
            Dict z wynikiem operacji
        """
        return await self.queue_manager.resume()

    async def purge_queue(self) -> dict:
        """
        Usuwa wszystkie zadania o statusie PENDING z kolejki.

        Returns:
            Dict z wynikiem operacji (liczba usuniÄ™tych zadaÅ„)
        """
        return await self.queue_manager.purge()

    async def abort_task(self, task_id: UUID) -> dict:
        """
        Przerywa wykonywanie konkretnego zadania.

        Args:
            task_id: ID zadania do przerwania

        Returns:
            Dict z wynikiem operacji
        """
        return await self.queue_manager.abort_task(task_id)

    async def emergency_stop(self) -> dict:
        """
        Awaryjne zatrzymanie - przerywa wszystkie aktywne zadania i czyÅ›ci kolejkÄ™.

        Returns:
            Dict z wynikiem operacji
        """
        return await self.queue_manager.emergency_stop()

    def get_queue_status(self) -> dict:
        """
        Zwraca aktualny status kolejki zadaÅ„.

        Returns:
            Dict ze statusem kolejki
        """
        return self.queue_manager.get_status()

    def get_token_economist(self):
        """
        Zwraca instancjÄ™ TokenEconomist z task_dispatcher.

        Returns:
            TokenEconomist lub None jeÅ›li nie jest dostÄ™pny

        Raises:
            NotImplementedError: Funkcja nie jest jeszcze w peÅ‚ni zaimplementowana
        """
        raise NotImplementedError(
            "get_token_economist niezaimplementowane - dodaÄ‡ getter w KernelBuilder"
        )

    NON_LEARNING_INTENTS = {
        "TIME_REQUEST",
        "INFRA_STATUS",
    }

    NON_LLM_INTENTS = {
        "TIME_REQUEST",
        "INFRA_STATUS",
        "UNSUPPORTED_TASK",
    }

    KERNEL_FUNCTION_INTENTS = {
        "CODE_GENERATION",
        "KNOWLEDGE_SEARCH",
        "FILE_OPERATION",
        "RESEARCH",
        "VERSION_CONTROL",
        "TOOL_CREATION",
        "E2E_TESTING",
        "DOCUMENTATION",
        "RELEASE_PROJECT",
    }

    def _build_error_envelope(
        self,
        *,
        error_code: str,
        error_message: str,
        error_details: Optional[dict] = None,
        stage: Optional[str] = None,
        retryable: bool = False,
        error_class: Optional[str] = None,
    ) -> dict:
        return {
            "error_code": error_code,
            "error_class": error_class or error_code,
            "error_message": error_message,
            "error_details": error_details or {},
            "stage": stage,
            "retryable": retryable,
        }

    def _set_runtime_error(self, task_id: UUID, envelope: dict) -> None:
        self.state_manager.update_context(
            task_id,
            {
                "llm_runtime": {
                    "status": "error",
                    "error": envelope,
                    "last_error_at": datetime.now().isoformat(),
                }
            },
        )
        if self.request_tracer:
            self.request_tracer.set_error_metadata(task_id, envelope)

    def _should_store_lesson(
        self,
        request: TaskRequest,
        intent: str = "",
        agent=None,
    ) -> bool:
        """
        Sprawdza czy naleÅ¼y zapisaÄ‡ lekcjÄ™ dla danego zadania.

        Args:
            request: Oryginalne Å¼Ä…danie zadania
            intent: Sklasyfikowana intencja
            agent: Opcjonalny agent

        Returns:
            True jeÅ›li lekcja powinna byÄ‡ zapisana
        """
        # Deleguj do LessonsManager
        return self.lessons_manager.should_store_lesson(request, intent, agent)

    async def _run_task(self, task_id: UUID, request: TaskRequest) -> None:
        """
        Wykonuje zadanie w tle.

        Args:
            task_id: ID zadania do wykonania
            request: Oryginalne Å¼Ä…danie (z obrazami jeÅ›li sÄ…)
        """
        # Inicjalizuj zmienne dla error handling
        context = request.content
        intent = "UNKNOWN"
        result = ""
        tool_required = False

        try:
            # Pobierz zadanie
            task = self.state_manager.get_task(task_id)
            if task is None:
                logger.error(f"Zadanie {task_id} nie istnieje")
                return

            # Ustaw status PROCESSING
            await self.state_manager.update_status(task_id, TaskStatus.PROCESSING)
            self.state_manager.add_log(
                task_id, f"RozpoczÄ™to przetwarzanie: {datetime.now().isoformat()}"
            )

            # Aktualizuj tracer
            if self.request_tracer:
                self.request_tracer.update_status(task_id, TraceStatus.PROCESSING)
                self.request_tracer.add_step(
                    task_id, "Orchestrator", "start_processing", status="ok"
                )

            # Broadcast rozpoczÄ™cia zadania
            await self._broadcast_event(
                event_type="TASK_STARTED",
                message=f"Rozpoczynam przetwarzanie zadania {task_id}",
                data={"task_id": str(task_id)},
            )

            logger.info(f"Rozpoczynam przetwarzanie zadania {task_id}")

            # Przygotuj kontekst (treÅ›Ä‡ + analiza obrazÃ³w jeÅ›li sÄ…)
            context = await self._prepare_context(task_id, request)

            # Zapisz generation_params w kontekÅ›cie zadania jeÅ›li zostaÅ‚y przekazane
            if request.generation_params:
                self.state_manager.update_context(
                    task_id, {"generation_params": request.generation_params}
                )
                logger.info(
                    f"Zapisano parametry generacji dla zadania {task_id}: {request.generation_params}"
                )

            # JeÅ›li to zadanie testu wydajnoÅ›ci, zakoÅ„cz je natychmiast (bez LLM)
            if self._is_perf_test_prompt(context):
                await self._complete_perf_test_task(task_id)
                return

            # Klasyfikuj intencjÄ™ uÅ¼ytkownika (bez domieszek z lekcji)
            intent = await self.intent_manager.classify_intent(context)
            intent_debug = getattr(self.intent_manager, "last_intent_debug", {})
            if intent_debug:
                self.state_manager.update_context(
                    task_id, {"intent_debug": intent_debug}
                )
                if self.request_tracer:
                    try:
                        import json

                        details = json.dumps(intent_debug, ensure_ascii=False)
                    except Exception:
                        details = str(intent_debug)
                    self.request_tracer.add_step(
                        task_id,
                        "DecisionGate",
                        "intent_debug",
                        status="ok",
                        details=details,
                    )

            if (
                self.request_tracer
                and intent in self.NON_LLM_INTENTS
                and intent_debug.get("source") != "llm"
            ):
                self.request_tracer.set_llm_metadata(
                    task_id, provider=None, model=None, endpoint=None
                )
                self.state_manager.update_context(
                    task_id,
                    {
                        "llm_runtime": {
                            "status": "skipped",
                            "error": None,
                            "last_success_at": None,
                        }
                    },
                )

            tool_required = self.intent_manager.requires_tool(intent)
            self.state_manager.update_context(
                task_id,
                {"tool_requirement": {"required": tool_required, "intent": intent}},
            )
            if self.request_tracer:
                self.request_tracer.add_step(
                    task_id,
                    "DecisionGate",
                    "tool_requirement",
                    status="ok",
                    details=f"Tool required: {tool_required}",
                )
            collector = metrics_module.metrics_collector
            if collector:
                if tool_required:
                    collector.increment_tool_required_request()
                else:
                    collector.increment_llm_only_request()

            if tool_required:
                agent = self.task_dispatcher.agent_map.get(intent)
                if agent is None or agent.__class__.__name__ == "UnsupportedAgent":
                    self.state_manager.add_log(
                        task_id,
                        f"Brak narzÄ™dzia dla intencji {intent} - routing do UnsupportedAgent",
                    )
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "route_unsupported",
                            status="ok",
                            details=f"Tool required but missing for intent={intent}",
                        )
                    intent = "UNSUPPORTED_TASK"

            kernel_required = tool_required or intent in self.KERNEL_FUNCTION_INTENTS
            if self.request_tracer:
                self.request_tracer.add_step(
                    task_id,
                    "DecisionGate",
                    "requirements_resolved",
                    status="ok",
                    details=f"tool_required={tool_required}, kernel_required={kernel_required}",
                )
            if kernel_required and not getattr(self.task_dispatcher, "kernel", None):
                if self.request_tracer:
                    self.request_tracer.add_step(
                        task_id,
                        "DecisionGate",
                        "capability_required",
                        status="ok",
                        details="kernel",
                    )
                    self.request_tracer.add_step(
                        task_id,
                        "DecisionGate",
                        "requirements_missing",
                        status="error",
                        details="missing=kernel",
                    )
                    self.request_tracer.add_step(
                        task_id,
                        "Execution",
                        "execution_contract_violation",
                        status="error",
                        details="kernel_required",
                    )
                envelope = self._build_error_envelope(
                    error_code="execution_contract_violation",
                    error_message="Missing required capability: kernel",
                    error_details={"missing": ["kernel"]},
                    stage="agent_precheck",
                    retryable=False,
                )
                self._set_runtime_error(task_id, envelope)
                raise RuntimeError("execution_contract_violation")

            runtime_info = get_active_llm_runtime()
            expected_hash = request.expected_config_hash or SETTINGS.LLM_CONFIG_HASH
            expected_runtime_id = request.expected_runtime_id
            actual_hash = runtime_info.config_hash or compute_llm_config_hash(
                runtime_info.provider, runtime_info.endpoint, runtime_info.model_name
            )
            if self.request_tracer:
                self.request_tracer.add_step(
                    task_id,
                    "Orchestrator",
                    "routing_resolved",
                    status="ok",
                    details=(
                        f"provider={runtime_info.provider}, model={runtime_info.model_name}, "
                        f"endpoint={runtime_info.endpoint}, hash={actual_hash}, runtime={runtime_info.runtime_id}"
                    ),
                )
            mismatch = False
            mismatch_details = []
            if expected_hash and actual_hash != expected_hash:
                mismatch = True
                mismatch_details.append(
                    f"expected_hash={expected_hash}, actual_hash={actual_hash}"
                )
            if expected_runtime_id and runtime_info.runtime_id != expected_runtime_id:
                mismatch = True
                mismatch_details.append(
                    f"expected_runtime={expected_runtime_id}, actual_runtime={runtime_info.runtime_id}"
                )
            if mismatch:
                if self.request_tracer:
                    self.request_tracer.add_step(
                        task_id,
                        "Orchestrator",
                        "routing_mismatch",
                        status="error",
                        details="; ".join(mismatch_details),
                    )
                envelope = self._build_error_envelope(
                    error_code="routing_mismatch",
                    error_message="Active runtime does not match expected configuration.",
                    error_details={
                        "expected_hash": expected_hash,
                        "actual_hash": actual_hash,
                        "expected_runtime": expected_runtime_id,
                        "actual_runtime": runtime_info.runtime_id,
                    },
                    stage="routing",
                    retryable=False,
                )
                self._set_runtime_error(task_id, envelope)
                raise RuntimeError("routing_mismatch")

            # PRE-FLIGHT CHECK: SprawdÅº czy sÄ… lekcje z przeszÅ‚oÅ›ci (tylko dla LLM-only)
            if intent not in self.NON_LEARNING_INTENTS and not tool_required:
                context = await self.lessons_manager.add_lessons_to_context(task_id, context)
                hidden_context = build_hidden_prompts_context(
                    intent=intent, limit=MAX_HIDDEN_PROMPTS_IN_CONTEXT
                )
                if hidden_context:
                    context = hidden_context + "\n\n" + context
                    self.state_manager.add_log(
                        task_id,
                        "DoÅ‚Ä…czono hidden prompts do kontekstu",
                    )
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "hidden_prompts",
                            status="ok",
                            details=f"Hidden prompts: {MAX_HIDDEN_PROMPTS_IN_CONTEXT}",
                        )

            # Zaloguj sklasyfikowanÄ… intencjÄ™
            self.state_manager.add_log(
                task_id,
                f"Sklasyfikowana intencja: {intent} - {datetime.now().isoformat()}",
            )

            # Dodaj krok do tracera
            if self.request_tracer:
                self.request_tracer.add_step(
                    task_id,
                    "Orchestrator",
                    "classify_intent",
                    status="ok",
                    details=f"Intent: {intent}",
                )

            # Broadcast intencji
            await self._broadcast_event(
                event_type="AGENT_THOUGHT",
                message=f"Rozpoznano intencjÄ™: {intent}",
                data={"task_id": str(task_id), "intent": intent},
            )

            # UtwÃ³rz callback streamingu uÅ¼ywajÄ…c StreamingHandler
            stream_callback = self.streaming_handler.create_stream_callback(task_id)
            stream_token = set_llm_stream_callback(stream_callback)

            # SPECJALNE PRZYPADKI: START_CAMPAIGN
            try:
                if intent == "START_CAMPAIGN":
                    # Uruchom tryb kampanii
                    self.state_manager.add_log(
                        task_id, "ğŸš€ Uruchamiam Tryb Kampanii (Campaign Mode)"
                    )
                    # Decision Gate: START_CAMPAIGN
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "route_campaign",
                            status="ok",
                            details="ğŸš€ Routing to Campaign Mode",
                        )
                    # Lazy init CampaignFlow
                    if self._campaign_flow is None:
                        self._campaign_flow = CampaignFlow(
                            state_manager=self.state_manager,
                            orchestrator_submit_task=self.submit_task,
                            event_broadcaster=self.event_broadcaster,
                        )
                    campaign_result = await self._campaign_flow.execute(
                        goal_store=self.task_dispatcher.goal_store
                    )
                    result = campaign_result.get("summary", str(campaign_result))

                # SPECJALNE PRZYPADKI: HELP_REQUEST
                elif intent == "HELP_REQUEST":
                    # Wygeneruj dynamicznÄ… odpowiedÅº pomocy
                    self.state_manager.add_log(task_id, "â“ GenerujÄ™ informacje pomocy")
                    # Decision Gate: HELP_REQUEST
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "route_help",
                            status="ok",
                            details="â“ Routing to Help System",
                        )
                    result = await self._generate_help_response(task_id)

                # DECYZJA: Council mode vs Standard mode
                elif self._should_use_council(context, intent):
                    # Tryb Council - autonomiczna dyskusja agentÃ³w
                    self.state_manager.add_log(
                        task_id,
                        "ğŸ›ï¸ Zadanie wymaga wspÃ³Å‚pracy - aktywujÄ™ The Council",
                    )
                    # Decision Gate: Council mode
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "select_council_mode",
                            status="ok",
                            details=f"ğŸ›ï¸ Complex task detected (intent={intent}) -> Council Mode",
                        )
                    result = await self.run_council(task_id, context)
                elif intent == "CODE_GENERATION":
                    # Standardowy tryb - pÄ™tla Coder-Critic
                    # Decision Gate: Code Generation with Review Loop
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "select_code_review_loop",
                            status="ok",
                            details="ğŸ’» Routing to Coder-Critic Review Loop",
                        )
                    result = await self._code_generation_with_review(task_id, context)
                elif intent == "COMPLEX_PLANNING":
                    # Standardowy tryb - delegacja do Architekta
                    self.state_manager.add_log(
                        task_id,
                        "Zadanie sklasyfikowane jako COMPLEX_PLANNING - delegacja do Architekta",
                    )
                    # Decision Gate: Complex Planning -> Architect
                    if self.request_tracer:
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "route_to_architect",
                            status="ok",
                            details="ğŸ—ï¸ Routing to Architect for Complex Planning",
                        )
                    await self._broadcast_event(
                        event_type="AGENT_ACTION",
                        message="PrzekazujÄ™ zadanie do Architekta (Complex Planning)",
                        agent="Architect",
                        data={"task_id": str(task_id)},
                    )
                    result = await self.task_dispatcher.dispatch(
                        intent, context, generation_params=request.generation_params
                    )
                else:
                    # Dla pozostaÅ‚ych intencji (RESEARCH, GENERAL_CHAT, KNOWLEDGE_SEARCH, itp.) - standardowy przepÅ‚yw
                    # Decision Gate: Standard dispatch
                    if self.request_tracer:
                        agent = self.task_dispatcher.agent_map.get(intent)
                        agent_name = (
                            agent.__class__.__name__ if agent else "UnknownAgent"
                        )
                        self.request_tracer.add_step(
                            task_id,
                            "DecisionGate",
                            "route_to_agent",
                            status="ok",
                            details=f"ğŸ“¤ Routing to {agent_name} (intent={intent})",
                        )
                    result = await self.task_dispatcher.dispatch(
                        intent, context, generation_params=request.generation_params
                    )
            finally:
                reset_llm_stream_callback(stream_token)

            # Zaloguj ktÃ³re agent przejÄ…Å‚ zadanie
            agent = self.task_dispatcher.agent_map.get(intent)
            if agent is not None:
                agent_name = agent.__class__.__name__
                self.state_manager.add_log(
                    task_id,
                    f"Agent {agent_name} przetworzyÅ‚ zadanie - {datetime.now().isoformat()}",
                )
                # Dodaj krok do tracera
                if self.request_tracer:
                    self.request_tracer.add_step(
                        task_id,
                        agent_name,
                        "process_task",
                        status="ok",
                        details="Task processed successfully",
                    )
                # Inkrementuj licznik uÅ¼ycia agenta
                collector = metrics_module.metrics_collector
                if collector:
                    collector.increment_agent_usage(agent_name)

                # WyÅ›lij odpowiedÅº agenta do dashboardu (np. ChatAgent)
                formatted_result = ""
                if isinstance(result, (dict, list)):
                    import json

                    try:
                        formatted_result = json.dumps(
                            result, ensure_ascii=False, indent=2
                        )
                    except Exception:
                        formatted_result = str(result)
                else:
                    formatted_result = str(result)

                if formatted_result.strip():
                    await self._broadcast_event(
                        event_type="AGENT_ACTION",
                        message=formatted_result,
                        agent=agent_name,
                        data={
                            "task_id": str(task_id),
                            "intent": intent,
                        },
                    )
            else:
                logger.error(
                    f"Nie znaleziono agenta dla intencji '{intent}' podczas logowania zadania {task_id}"
                )

            # Ustaw status COMPLETED i wynik
            await self.state_manager.update_status(
                task_id, TaskStatus.COMPLETED, result=result
            )
            self.state_manager.add_log(
                task_id, f"ZakoÅ„czono przetwarzanie: {datetime.now().isoformat()}"
            )
            self.state_manager.update_context(
                task_id,
                {
                    "llm_runtime": {
                        "status": "ready",
                        "error": None,
                        "last_success_at": datetime.now().isoformat(),
                    }
                },
            )

            # Aktualizuj tracer
            if self.request_tracer:
                self.request_tracer.update_status(task_id, TraceStatus.COMPLETED)
                self.request_tracer.add_step(
                    task_id, "System", "complete", status="ok", details="Response sent"
                )

            # REFLEKSJA: Zapisz lekcjÄ™ o sukcesie (jeÅ›li meta-uczenie wÅ‚Ä…czone i store_knowledge=True)
            if self._should_store_lesson(request, intent=intent, agent=agent):
                await self.lessons_manager.save_task_lesson(
                    task_id=task_id,
                    context=context,
                    intent=intent,
                    result=result,
                    success=True,
                    agent=agent,
                    request=request,
                )
            else:
                logger.info(
                    f"Skipping lesson save for task {task_id} (Knowledge Storage Disabled)"
                )

            if self.lessons_manager.should_log_learning(
                request, intent=intent, tool_required=tool_required, agent=agent
            ):
                self.lessons_manager.append_learning_log(
                    task_id=task_id,
                    intent=intent,
                    prompt=request.content,
                    result=result,
                    success=True,
                )

            # Inkrementuj licznik ukoÅ„czonych zadaÅ„
            collector = metrics_module.metrics_collector
            if collector:
                collector.increment_task_completed()

            # Broadcast ukoÅ„czenia zadania
            await self._broadcast_event(
                event_type="TASK_COMPLETED",
                message=f"Zadanie {task_id} zakoÅ„czone sukcesem",
                data={"task_id": str(task_id), "result_length": len(result)},
            )

            logger.info(f"Zadanie {task_id} zakoÅ„czone sukcesem")

        except Exception as e:
            # ObsÅ‚uga bÅ‚Ä™dÃ³w - ustaw status FAILED
            logger.error(f"BÅ‚Ä…d podczas przetwarzania zadania {task_id}: {e}")
            task = self.state_manager.get_task(task_id)
            existing_error = None
            if task:
                runtime_ctx = task.context_history.get("llm_runtime", {}) or {}
                if isinstance(runtime_ctx, dict):
                    existing_error = runtime_ctx.get("error")
            if not (
                isinstance(existing_error, dict) and existing_error.get("error_code")
            ):
                envelope = self._build_error_envelope(
                    error_code="agent_error",
                    error_message=str(e) or "Unhandled agent error",
                    error_details={"exception": e.__class__.__name__},
                    stage="agent_runtime",
                    retryable=False,
                )
                self._set_runtime_error(task_id, envelope)

            # Aktualizuj tracer
            if self.request_tracer:
                self.request_tracer.update_status(task_id, TraceStatus.FAILED)
                self.request_tracer.add_step(
                    task_id,
                    "System",
                    "error",
                    status="error",
                    details=f"Error: {str(e)}",
                )

            # REFLEKSJA: Zapisz lekcjÄ™ o bÅ‚Ä™dzie (jeÅ›li meta-uczenie wÅ‚Ä…czone i store_knowledge=True)
            agent = self.task_dispatcher.agent_map.get(intent)
            if self._should_store_lesson(request, intent=intent, agent=agent):
                await self.lessons_manager.save_task_lesson(
                    task_id=task_id,
                    context=context,
                    intent=intent,
                    result=f"BÅ‚Ä…d: {str(e)}",
                    success=False,
                    error=str(e),
                    agent=agent,
                    request=request,
                )
            else:
                logger.info(
                    f"Skipping lesson save for task {task_id} (Knowledge Storage Disabled)"
                )

            if self.lessons_manager.should_log_learning(
                request, intent=intent, tool_required=tool_required, agent=agent
            ):
                self.lessons_manager.append_learning_log(
                    task_id=task_id,
                    intent=intent,
                    prompt=request.content,
                    result=f"BÅ‚Ä…d: {str(e)}",
                    success=False,
                    error=str(e),
                )

            # Inkrementuj licznik nieudanych zadaÅ„
            collector = metrics_module.metrics_collector
            if collector:
                collector.increment_task_failed()

            # Broadcast bÅ‚Ä™du
            await self._broadcast_event(
                event_type="TASK_FAILED",
                message=f"Zadanie {task_id} nie powiodÅ‚o siÄ™: {str(e)}",
                data={"task_id": str(task_id), "error": str(e)},
            )

            try:
                await self.state_manager.update_status(
                    task_id, TaskStatus.FAILED, result=f"BÅ‚Ä…d: {str(e)}"
                )
                self.state_manager.add_log(
                    task_id,
                    f"BÅ‚Ä…d przetwarzania: {str(e)} - {datetime.now().isoformat()}",
                )
            except Exception as log_error:
                logger.error(
                    f"Nie udaÅ‚o siÄ™ zapisaÄ‡ bÅ‚Ä™du zadania {task_id}: {log_error}"
                )

    def _is_perf_test_prompt(self, content: str) -> bool:
        """SprawdÅº, czy treÅ›Ä‡ zadania pochodzi z testÃ³w wydajnoÅ›ci."""
        keywords = getattr(IntentManager, "PERF_TEST_KEYWORDS", ())
        normalized = (content or "").lower()
        return any(keyword in normalized for keyword in keywords)

    async def _complete_perf_test_task(self, task_id: UUID) -> None:
        """ZakoÅ„cz zadanie testu wydajnoÅ›ci bez uruchamiania peÅ‚nego pipeline'u."""
        result_text = "âœ… Backend perf pipeline OK"
        self.state_manager.add_log(
            task_id,
            "âš¡ Wykryto prompt testu wydajnoÅ›ci â€“ pomijam kosztowne agentÃ³w i zamykam zadanie natychmiast.",
        )
        await self.state_manager.update_status(
            task_id, TaskStatus.COMPLETED, result=result_text
        )
        self.state_manager.add_log(
            task_id, f"ZakoÅ„czono test wydajnoÅ›ci: {datetime.now().isoformat()}"
        )

        if self.request_tracer:
            self.request_tracer.update_status(task_id, TraceStatus.COMPLETED)
            self.request_tracer.add_step(
                task_id,
                "System",
                "perf_test_shortcut",
                status="ok",
                details="Perf test zakoÅ„czony bez agentÃ³w",
            )

        collector = metrics_module.metrics_collector
        if collector:
            collector.increment_task_completed()

        await self._broadcast_event(
            event_type="TASK_COMPLETED",
            message=f"Zadanie {task_id} zakoÅ„czone (perf test)",
            data={"task_id": str(task_id), "result_length": len(result_text)},
        )

        logger.info(f"Zadanie {task_id} zakoÅ„czone w trybie perf-test")

    async def _prepare_context(self, task_id: UUID, request: TaskRequest) -> str:
        """
        Przygotowuje kontekst zadania (treÅ›Ä‡ + analiza obrazÃ³w).

        Args:
            task_id: ID zadania
            request: Å»Ä…danie z treÅ›ciÄ… i opcjonalnymi obrazami

        Returns:
            PeÅ‚ny kontekst do przetworzenia
        """
        context = request.content

        # JeÅ›li sÄ… obrazy, przeanalizuj je
        if request.images:
            self.state_manager.add_log(
                task_id, f"AnalizujÄ™ {len(request.images)} obrazÃ³w..."
            )

            for i, image in enumerate(request.images, 1):
                try:
                    description = await self.eyes.analyze_image(
                        image,
                        prompt="Opisz szczegÃ³Å‚owo co widzisz na tym obrazie, szczegÃ³lnie zwrÃ³Ä‡ uwagÄ™ na tekst, bÅ‚Ä™dy lub problemy.",
                    )
                    context += f"\n\n[OBRAZ {i}]: {description}"
                    self.state_manager.add_log(
                        task_id, f"Obraz {i} przeanalizowany pomyÅ›lnie"
                    )
                except Exception as e:
                    logger.error(f"BÅ‚Ä…d podczas analizy obrazu {i}: {e}")
                    self.state_manager.add_log(
                        task_id, f"Nie udaÅ‚o siÄ™ przeanalizowaÄ‡ obrazu {i}: {e}"
                    )

        return context

    async def _code_generation_with_review(
        self, task_id: UUID, user_request: str
    ) -> str:
        """
        PÄ™tla generowania kodu z ocenÄ… przez CriticAgent.

        Args:
            task_id: ID zadania
            user_request: Å»Ä…danie uÅ¼ytkownika

        Returns:
            Zaakceptowany kod lub kod po naprawach
        """
        coder = getattr(self.task_dispatcher, "coder_agent", None)
        critic = getattr(self.task_dispatcher, "critic_agent", None)

        if coder is None or critic is None:
            logger.warning(
                "TaskDispatcher nie ma zainicjalizowanych agentÃ³w coder/critic - uÅ¼ywam prostego dispatch"
            )
            return await self.task_dispatcher.dispatch("CODE_GENERATION", user_request)

        # Lazy init CodeReviewLoop
        if self._code_review_loop is None:
            self._code_review_loop = CodeReviewLoop(
                state_manager=self.state_manager,
                coder_agent=coder,
                critic_agent=critic,
            )

        # Deleguj do CodeReviewLoop
        return await self._code_review_loop.execute(task_id, user_request)

    def _should_use_council(self, context: str, intent: str) -> bool:
        """
        Decyduje czy uÅ¼yÄ‡ trybu Council dla danego zadania.

        Args:
            context: Kontekst zadania
            intent: Sklasyfikowana intencja

        Returns:
            True jeÅ›li naleÅ¼y uÅ¼yÄ‡ Council, False dla standardowego flow
        """
        # Lazy init CouncilFlow
        if self._council_flow is None:
            self._council_flow = CouncilFlow(
                state_manager=self.state_manager,
                task_dispatcher=self.task_dispatcher,
                event_broadcaster=self.event_broadcaster,
            )
            # Zaktualizuj flow_router z council_flow
            self.flow_router._council_flow = self._council_flow

        # Deleguj decyzjÄ™ do FlowRouter
        return self.flow_router.should_use_council(context, intent)

    async def run_council(self, task_id: UUID, context: str) -> str:
        """
        Uruchamia tryb Council (AutoGen Group Chat) dla zÅ‚oÅ¼onych zadaÅ„.

        W tym trybie agenci prowadzÄ… autonomicznÄ… dyskusjÄ™:
        - Architect planuje
        - Coder implementuje
        - Critic sprawdza
        - Guardian weryfikuje testy

        Args:
            task_id: ID zadania
            context: Kontekst zadania

        Returns:
            Wynik dyskusji Council
        """
        self.state_manager.add_log(
            task_id, "ğŸ›ï¸ THE COUNCIL: Rozpoczynam tryb Group Chat (Swarm Intelligence)"
        )

        await self._broadcast_event(
            event_type="COUNCIL_STARTED",
            message="The Council rozpoczyna dyskusjÄ™ nad zadaniem",
            data={"task_id": str(task_id)},
        )

        try:
            if self._council_config is None:
                from venom_core.agents.guardian import GuardianAgent
                from venom_core.core.council import (
                    CouncilConfig,
                    create_local_llm_config,
                )

                coder = getattr(self.task_dispatcher, "coder_agent", None)
                critic = getattr(self.task_dispatcher, "critic_agent", None)
                architect = getattr(self.task_dispatcher, "architect_agent", None)

                guardian = GuardianAgent(kernel=self.task_dispatcher.kernel)
                llm_config = create_local_llm_config()

                self._council_config = CouncilConfig(
                    coder_agent=coder,
                    critic_agent=critic,
                    architect_agent=architect,
                    guardian_agent=guardian,
                    llm_config=llm_config,
                )

            from venom_core.core.council import CouncilSession

            council_tuple = self._council_config.create_council()
            user_proxy, group_chat, manager = self._normalize_council_tuple(
                council_tuple
            )

            session = CouncilSession(user_proxy, group_chat, manager)

            members = []
            if group_chat is not None and getattr(group_chat, "agents", None):
                members = [
                    getattr(agent, "name", str(agent)) for agent in group_chat.agents
                ]

            await self._broadcast_event(
                event_type="COUNCIL_MEMBERS",
                message=f"Council skÅ‚ada siÄ™ z {len(members)} czÅ‚onkÃ³w",
                data={"task_id": str(task_id), "members": members},
            )

            result = await session.run(context)

            get_message_count = getattr(session, "get_message_count", lambda: 0)
            get_speakers = getattr(session, "get_speakers", lambda: members)
            message_count = get_message_count()
            speakers = get_speakers() or members

            self.state_manager.add_log(
                task_id,
                f"ğŸ›ï¸ THE COUNCIL: Dyskusja zakoÅ„czona - {message_count} wiadomoÅ›ci, "
                f"uczestnicy: {', '.join(speakers)}",
            )

            await self._broadcast_event(
                event_type="COUNCIL_COMPLETED",
                message=f"Council zakoÅ„czyÅ‚ dyskusjÄ™ po {message_count} wiadomoÅ›ciach",
                data={
                    "task_id": str(task_id),
                    "message_count": message_count,
                    "speakers": speakers,
                },
            )

            logger.info(f"Council zakoÅ„czyÅ‚ zadanie {task_id}")
            return result

        except Exception as e:
            error_msg = f"âŒ BÅ‚Ä…d podczas dziaÅ‚ania Council: {e}"
            logger.error(error_msg)

            self.state_manager.add_log(task_id, error_msg)

            await self._broadcast_event(
                event_type="COUNCIL_ERROR",
                message=error_msg,
                data={"task_id": str(task_id), "error": str(e)},
            )

            logger.warning("Council zawiÃ³dÅ‚ - powrÃ³t do standardowego flow")
            return f"Council mode nie powiÃ³dÅ‚ siÄ™: {e}"

    def _normalize_council_tuple(self, council_result):
        """Zapewnia Å¼e create_council zwraca krotkÄ™ (user_proxy, group_chat, manager)."""

        if isinstance(council_result, tuple):
            padded = list(council_result) + [None] * (3 - len(council_result))
            return tuple(padded[:3])

        user_proxy = getattr(council_result, "user_proxy", None)
        group_chat = getattr(council_result, "group_chat", None)
        manager = getattr(council_result, "manager", None)
        return user_proxy, group_chat, manager

    async def execute_healing_cycle(self, task_id: UUID, test_path: str = ".") -> dict:
        """
        PÄ™tla samonaprawy (Test-Diagnose-Fix-Apply).

        Delegowane do HealingFlow.

        Args:
            task_id: ID zadania
            test_path: ÅšcieÅ¼ka do testÃ³w

        Returns:
            SÅ‚ownik z wynikami (success, iterations, final_report)
        """
        # Lazy init HealingFlow
        if self._healing_flow is None:
            self._healing_flow = HealingFlow(
                state_manager=self.state_manager,
                task_dispatcher=self.task_dispatcher,
                event_broadcaster=self.event_broadcaster,
            )

        return await self._healing_flow.execute(task_id, test_path)

    async def execute_forge_workflow(
        self, task_id: UUID, tool_specification: str, tool_name: str
    ) -> dict:
        """
        Wykonuje workflow "The Forge" - tworzenie nowego narzÄ™dzia.

        Algorytm:
        1. CRAFT: Toolmaker generuje kod narzÄ™dzia
        2. TEST: Toolmaker generuje test jednostkowy
        3. VERIFY: Guardian testuje narzÄ™dzie w Dockerze
        4. LOAD: SkillManager Å‚aduje narzÄ™dzie do Kernela

        Args:
            task_id: ID zadania
            tool_specification: Specyfikacja narzÄ™dzia (co ma robiÄ‡)
            tool_name: Nazwa narzÄ™dzia (snake_case, bez .py)

        Returns:
            SÅ‚ownik z wynikami:
            - success: bool - czy narzÄ™dzie zostaÅ‚o stworzone i zaÅ‚adowane
            - tool_name: str - nazwa narzÄ™dzia
            - message: str - opis wyniku
            - code: str - wygenerowany kod (jeÅ›li sukces)
        """
        # Lazy init ForgeFlow
        if self._forge_flow is None:
            self._forge_flow = ForgeFlow(
                state_manager=self.state_manager,
                task_dispatcher=self.task_dispatcher,
                event_broadcaster=self.event_broadcaster,
            )

        # Deleguj do ForgeFlow
        return await self._forge_flow.execute(task_id, tool_specification, tool_name)

    async def handle_remote_issue(self, issue_number: int) -> dict:
        """
        ObsÅ‚uguje Issue z GitHub: pobiera szczegÃ³Å‚y, tworzy plan, implementuje fix, tworzy PR.

        Delegowane do IssueHandlerFlow.

        Args:
            issue_number: Numer Issue do obsÅ‚uÅ¼enia

        Returns:
            Dict z wynikiem operacji
        """
        # Lazy init IssueHandlerFlow
        if self._issue_handler_flow is None:
            self._issue_handler_flow = IssueHandlerFlow(
                state_manager=self.state_manager,
                task_dispatcher=self.task_dispatcher,
                event_broadcaster=self.event_broadcaster,
            )

        return await self._issue_handler_flow.execute(issue_number)

    async def execute_campaign_mode(
        self, goal_store=None, max_iterations: int = 10
    ) -> dict:
        """
        Tryb Kampanii - autonomiczna realizacja roadmapy.

        Delegowane do CampaignFlow.

        Args:
            goal_store: Magazyn celÃ³w (GoalStore)
            max_iterations: Maksymalna liczba iteracji (zabezpieczenie)

        Returns:
            Dict z wynikami kampanii
        """
        # Ta metoda juÅ¼ jest wywoÅ‚ywana przez _campaign_flow w _run_task
        # ale zostawiamy jÄ… dla kompatybilnoÅ›ci wstecznej
        if self._campaign_flow is None:
            self._campaign_flow = CampaignFlow(
                state_manager=self.state_manager,
                orchestrator_submit_task=self.submit_task,
                event_broadcaster=self.event_broadcaster,
            )

        return await self._campaign_flow.execute(goal_store, max_iterations)

    async def _generate_help_response(self, task_id: UUID) -> str:
        """
        Generuje dynamicznÄ… odpowiedÅº pomocy z informacjami o dostÄ™pnych umiejÄ™tnoÅ›ciach.

        Args:
            task_id: ID zadania

        Returns:
            Sformatowana odpowiedÅº pomocy w formacie Markdown
        """
        try:
            # Pobierz informacje o dostÄ™pnych agentach z dispatcher
            agent_map = self.task_dispatcher.agent_map

            # Pobierz informacje o umiejÄ™tnoÅ›ciach z kernela
            kernel = self.task_dispatcher.kernel
            plugins = getattr(kernel, "plugins", None)

            # Buduj odpowiedÅº pomocy
            help_text = """# ğŸ•·ï¸ Venom - System Pomocy

## DostÄ™pne MoÅ¼liwoÅ›ci

Jestem Venom - wieloagentowy system AI wspierajÄ…cy rozwÃ³j oprogramowania. Oto co mogÄ™ dla Ciebie zrobiÄ‡:

### ğŸ¤– DostÄ™pni Agenci

"""

            # Dodaj informacje o agentach
            agent_descriptions = {
                "CODE_GENERATION": "ğŸ’» **Coder** - Generowanie, refaktoryzacja i naprawa kodu",
                "RESEARCH": "ğŸ” **Researcher** - Wyszukiwanie aktualnych informacji w Internecie",
                "KNOWLEDGE_SEARCH": "ğŸ“š **Professor** - Odpowiedzi na pytania o wiedzÄ™ i technologie",
                "COMPLEX_PLANNING": "ğŸ—ï¸ **Architect** - Projektowanie zÅ‚oÅ¼onych systemÃ³w i aplikacji",
                "VERSION_CONTROL": "ğŸŒ¿ **Git Master** - ZarzÄ…dzanie gaÅ‚Ä™ziami, commitami i synchronizacjÄ…",
                "E2E_TESTING": "ğŸ§ª **Tester** - Testowanie aplikacji webowych end-to-end",
                "DOCUMENTATION": "ğŸ“– **Publisher** - Generowanie i publikacja dokumentacji",
                "RELEASE_PROJECT": "ğŸš€ **Release Manager** - ZarzÄ…dzanie wydaniami i changelog",
                "STATUS_REPORT": "ğŸ“Š **Executive** - Raportowanie statusu i postÄ™pu projektu",
                "GENERAL_CHAT": "ğŸ’¬ **Assistant** - OgÃ³lna konwersacja i wsparcie",
            }

            for intent, description in agent_descriptions.items():
                if intent in agent_map:
                    help_text += f"- {description}\n"

            # Dodaj informacje o trybach pracy
            help_text += """
### ğŸ¯ Tryby Pracy

- **ğŸ›ï¸ The Council** - Autonomiczna wspÃ³Å‚praca agentÃ³w dla zÅ‚oÅ¼onych projektÃ³w
- **ğŸš€ Tryb Kampanii** - Automatyczna realizacja roadmapy projektu
- **ğŸ”„ PÄ™tla Samonaprawy** - Automatyczne testowanie i naprawianie kodu

### ğŸ› ï¸ UmiejÄ™tnoÅ›ci (Skills)

"""

            # Dodaj listÄ™ dostÄ™pnych pluginÃ³w
            if plugins is not None:
                skill_count = 0
                for plugin_name in plugins:
                    # Filtruj wewnÄ™trzne pluginy
                    if self._is_public_plugin(plugin_name):
                        skill_count += 1
                        help_text += f"- **{plugin_name}**\n"

                if skill_count == 0:
                    help_text += "- Trwa Å‚adowanie umiejÄ™tnoÅ›ci...\n"
            else:
                help_text += "- Podstawowe umiejÄ™tnoÅ›ci: manipulacja plikami, Git, shell, research, renderowanie\n"

            # Dodaj przykÅ‚ady uÅ¼ycia
            help_text += """
### ğŸ’¡ PrzykÅ‚ady UÅ¼ycia

**Generowanie kodu:**
```
Napisz funkcjÄ™ w Pythonie do sortowania listy
```

**Research:**
```
ZnajdÅº najnowsze informacje o FastAPI 0.100
```

**Projekt aplikacji:**
```
StwÃ³rz aplikacjÄ™ webowÄ… z FastAPI i React
```

**Git:**
```
UtwÃ³rz nowy branch feat/new-feature
```

**Dokumentacja:**
```
Wygeneruj dokumentacjÄ™ projektu
```

### â„¹ï¸ Dodatkowe Informacje

- Wspieramy lokalne modele (Ollama) oraz API chmurowe (OpenAI, Azure)
- Automatyczne zarzÄ…dzanie pamiÄ™ciÄ… i uczenie siÄ™ z bÅ‚Ä™dÃ³w
- Integracja z GitHub, Docker i systemami CI/CD
- Voice interface (gdy wÅ‚Ä…czony)
- Distributed execution (tryb Nexus)

**Potrzebujesz pomocy?** Zapytaj o konkretnÄ… funkcjonalnoÅ›Ä‡ lub wyÅ›lij zadanie do wykonania!
"""

            # Broadcast zdarzenia renderowania widgetu pomocy
            if self.event_broadcaster:
                await self._broadcast_event(
                    event_type="RENDER_WIDGET",
                    message="WyÅ›wietlam system pomocy",
                    data={
                        "widget": {
                            "id": f"help-{task_id}",
                            "type": "markdown",
                            "data": {"content": help_text},
                        }
                    },
                )

            return help_text

        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas generowania pomocy: {e}")
            return "WystÄ…piÅ‚ bÅ‚Ä…d podczas generowania pomocy. SprÃ³buj ponownie lub skontaktuj siÄ™ z administratorem."

    def _is_public_plugin(self, plugin_name: str) -> bool:
        """
        Sprawdza czy plugin jest publiczny (nie wewnÄ™trzny).

        Args:
            plugin_name: Nazwa pluginu

        Returns:
            True jeÅ›li plugin jest publiczny
        """
        # Filtruj wewnÄ™trzne pluginy (zaczynajÄ…ce siÄ™ od _ lub zawierajÄ…ce 'internal')
        return not (plugin_name.startswith("_") or "internal" in plugin_name.lower())
