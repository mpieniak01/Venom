# ===== VENOM v2.0 Configuration Example =====
# Skopiuj ten plik do .env i uzupełnij wartości

# ===== BASIC CONFIGURATION =====
APP_NAME=Venom Meta-Intelligence
ENV=development
URL_SCHEME_POLICY=auto
NEXT_PUBLIC_URL_SCHEME_POLICY=auto

# ===== POLICY GATE =====
# Włącza globalny gate polityk bezpieczeństwa i etyki
# Domyślnie wyłączone dla bezpiecznego rolloutu
ENABLE_POLICY_GATE=false

WORKSPACE_ROOT=./workspace
REPO_ROOT=.
MEMORY_ROOT=./data/memory
STATE_FILE_PATH=./data/memory/state_dump.json
NETWORK_PROBE_HOST=dns.google
NETWORK_PROBE_PORT=80

# ===== AI CONFIGURATION (HYBRID ENGINE) =====

# AI Mode: LOCAL (tylko lokalne modele), HYBRID (mix local+cloud), CLOUD (głównie cloud)
AI_MODE=LOCAL

# Local LLM Configuration (Ollama/vLLM/Llama.cpp)
LLM_SERVICE_TYPE=local
ACTIVE_LLM_SERVER=
LLM_LOCAL_ENDPOINT=http://localhost:11434/v1
LLM_MODEL_NAME=llama3
LLM_LOCAL_API_KEY=venom-local
LLM_CONFIG_HASH=
SIMPLE_MODE_SYSTEM_PROMPT=Odpowiadaj po polsku.
LLM_WARMUP_ON_STARTUP=true
LLM_WARMUP_PROMPT=Ping.
LLM_WARMUP_TIMEOUT_SECONDS=5.0
LLM_WARMUP_MAX_TOKENS=8
LLM_KEEP_ALIVE=5m
MODEL_GENERATION_OVERRIDES=
# Strategia streszczeń: llm_with_fallback lub heuristic_only
SUMMARY_STRATEGY=llm_with_fallback
LAST_MODEL_OLLAMA=
LAST_MODEL_VLLM=
PREVIOUS_MODEL_OLLAMA=
PREVIOUS_MODEL_VLLM=

# vLLM (lokalny serwer OpenAI-compatible). Domyślnie serwujemy gemma-3-4b-it.
VLLM_MODEL_PATH=models/gemma-3-4b-it
VLLM_SERVED_MODEL_NAME=gemma-3-4b-it
VLLM_HOST=0.0.0.0
VLLM_PORT=8001
VLLM_GPU_MEMORY_UTILIZATION=0.85
VLLM_MAX_BATCHED_TOKENS=128
VLLM_MAX_MODEL_LEN=1024
VLLM_MAX_NUM_SEQS=2
VLLM_ENDPOINT=http://localhost:8001/v1
VLLM_CHAT_TEMPLATE=
VLLM_ENFORCE_EAGER=true
VLLM_START_COMMAND=bash ./scripts/llm/vllm_service.sh start
VLLM_STOP_COMMAND=bash ./scripts/llm/vllm_service.sh stop
VLLM_RESTART_COMMAND=bash ./scripts/llm/vllm_service.sh restart
OLLAMA_START_COMMAND=
OLLAMA_STOP_COMMAND=
OLLAMA_RESTART_COMMAND=

# Spójny profil generacji dla Gemma 3 (vLLM + Ollama)
MODEL_GENERATION_OVERRIDES={"vllm":{"gemma-3-4b-it":{"temperature":0.3,"top_p":0.9,"max_tokens":800}},"ollama":{"gemma3:4b":{"temperature":0.3,"top_p":0.9,"num_predict":800,"num_ctx":1024}}}

# Cloud Providers (opcjonalne, wymagane dla trybu HYBRID/CLOUD)
GOOGLE_API_KEY=
OPENAI_API_KEY=

# Hybrid Mode Settings
HYBRID_CLOUD_PROVIDER=google
HYBRID_LOCAL_MODEL=llama3
HYBRID_CLOUD_MODEL=gemini-1.5-pro
SENSITIVE_DATA_LOCAL_ONLY=true

# Model Routing
ENABLE_MODEL_ROUTING=true
FORCE_LOCAL_MODEL=false
ENABLE_MULTI_SERVICE=false
INTENT_CLASSIFIER_TIMEOUT_SECONDS=5.0
LOW_COST_FORCE_DDG=false
LESSONS_TTL_DAYS=0
MEMORY_TTL_DAYS=0
SESSION_TTL_DAYS=0

# ===== THE HIVE - Distributed Processing =====
# Architektura rozproszona z Redis message broker
ENABLE_HIVE=false
HIVE_URL=
HIVE_REGISTRATION_TOKEN=
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
HIVE_HIGH_PRIORITY_QUEUE=venom:tasks:high
HIVE_BACKGROUND_QUEUE=venom:tasks:background
HIVE_BROADCAST_CHANNEL=venom:broadcast
HIVE_TASK_TIMEOUT=300
HIVE_MAX_RETRIES=3
HIVE_ZOMBIE_TASK_TIMEOUT=600

# ===== THE NEXUS - Distributed Mesh =====
# Master-Worker architecture dla zdalnych węzłów
ENABLE_NEXUS=false
NEXUS_SHARED_TOKEN=
NEXUS_HEARTBEAT_TIMEOUT=60
NEXUS_PORT=8765

# ===== NETWORK & DISCOVERY =====
# mDNS (Zeroconf) dla lokalnej sieci - venom.local
# UWAGA: Cloudflare został usunięty, używamy lokalnego mDNS

# ===== BACKGROUND TASKS =====
VENOM_PAUSE_BACKGROUND_TASKS=false
ENABLE_AUTO_DOCUMENTATION=true
ENABLE_AUTO_GARDENING=true
ENABLE_MEMORY_CONSOLIDATION=false
ENABLE_HEALTH_CHECKS=true
WATCHER_DEBOUNCE_SECONDS=5
IDLE_THRESHOLD_MINUTES=15
GARDENER_COMPLEXITY_THRESHOLD=10
MEMORY_CONSOLIDATION_INTERVAL_MINUTES=60
HEALTH_CHECK_INTERVAL_MINUTES=5

# ===== EXTERNAL INTEGRATIONS =====
# HuggingFace Integration (opcjonalne)
ENABLE_HF_INTEGRATION=true
HF_TOKEN=

# GitHub Integration
GITHUB_TOKEN=
GITHUB_REPO_NAME=
ENABLE_ISSUE_POLLING=false
ISSUE_POLLING_INTERVAL_MINUTES=5

# Notifications
DISCORD_WEBHOOK_URL=
SLACK_WEBHOOK_URL=

# Tavily AI Search (opcjonalne, dla lepszej jakości wyszukiwania)
TAVILY_API_KEY=

# Google Calendar Integration (THE_CALENDAR)
ENABLE_GOOGLE_CALENDAR=false
GOOGLE_CALENDAR_CREDENTIALS_PATH=./data/config/google_calendar_credentials.json
GOOGLE_CALENDAR_TOKEN_PATH=./data/config/google_calendar_token.json
# IMPORTANT: VENOM_CALENDAR_ID must be a separate calendar ID, NOT 'primary'
# Create a new calendar in Google Calendar called "Venom Work" and use its ID here
# Safe Layering: read from primary, write ONLY to venom calendar
VENOM_CALENDAR_ID=venom_work_calendar
VENOM_CALENDAR_NAME=Venom Work

# ===== THE SHADOW - Desktop Awareness =====
ENABLE_PROACTIVE_MODE=false
ENABLE_DESKTOP_SENSOR=false
SHADOW_CONFIDENCE_THRESHOLD=0.8
SHADOW_PRIVACY_FILTER=true
SHADOW_CLIPBOARD_MAX_LENGTH=1000
SHADOW_CHECK_INTERVAL=1

# ===== THE GHOST - Visual GUI Automation =====
ENABLE_GHOST_AGENT=false
GHOST_MAX_STEPS=20
GHOST_STEP_DELAY=1.0
GHOST_VERIFICATION_ENABLED=true
GHOST_SAFETY_DELAY=0.5
GHOST_VISION_CONFIDENCE=0.7

# ===== BRAIN / GRAF WIEDZY =====
# Limity do ładowania grafów w /brain (frontend)
NEXT_PUBLIC_KNOWLEDGE_GRAPH_LIMIT=500
NEXT_PUBLIC_MEMORY_GRAPH_LIMIT=100

# ===== THE AVATAR - Audio Interface =====
ENABLE_AUDIO_INTERFACE=false
WHISPER_MODEL_SIZE=base
TTS_MODEL_PATH=
AUDIO_DEVICE=cpu
VAD_THRESHOLD=0.5
SILENCE_DURATION=1.5

# ===== THE ACADEMY - Knowledge Distillation =====
ENABLE_ACADEMY=true
ACADEMY_TRAINING_DIR=./data/training
ACADEMY_MODELS_DIR=./data/models
ACADEMY_MIN_LESSONS=100
ACADEMY_TRAINING_INTERVAL_HOURS=24
ACADEMY_DEFAULT_BASE_MODEL=unsloth/Phi-3-mini-4k-instruct
ACADEMY_LORA_RANK=16
ACADEMY_LEARNING_RATE=2e-4
ACADEMY_NUM_EPOCHS=3
ACADEMY_BATCH_SIZE=4
ACADEMY_MAX_SEQ_LENGTH=2048
ACADEMY_ENABLE_GPU=true
ACADEMY_USE_LOCAL_RUNTIME=true
ACADEMY_TRAINING_IMAGE=unsloth/unsloth:latest

# ===== THE DREAMER - Synthetic Experience =====
ENABLE_DREAMING=false
DREAMING_IDLE_THRESHOLD_MINUTES=30
DREAMING_NIGHT_HOURS=2-6
DREAMING_MAX_SCENARIOS=10
DREAMING_CPU_THRESHOLD=0.7
DREAMING_MEMORY_THRESHOLD=0.8
DREAMING_SCENARIO_COMPLEXITY=medium
DREAMING_VALIDATION_STRICT=true
DREAMING_OUTPUT_DIR=./data/synthetic_training
DREAMING_DOCKER_NAMESPACE=venom-dream-worker
DREAMING_PROCESS_PRIORITY=19

# ===== THE CHRONOMANCER - State Management =====
ENABLE_CHRONOS=true
CHRONOS_TIMELINES_DIR=./data/timelines
CHRONOS_AUTO_CHECKPOINT=true
CHRONOS_MAX_CHECKPOINTS_PER_TIMELINE=50
CHRONOS_CHECKPOINT_RETENTION_DAYS=30
CHRONOS_COMPRESS_SNAPSHOTS=true

# ===== THE LAUNCHPAD - Cloud Deployment =====
ENABLE_LAUNCHPAD=false
DEPLOYMENT_SSH_KEY_PATH=
DEPLOYMENT_DEFAULT_USER=root
DEPLOYMENT_TIMEOUT=300
ASSETS_DIR=./workspace/assets
ENABLE_IMAGE_GENERATION=true
IMAGE_GENERATION_SERVICE=placeholder
DALLE_MODEL=dall-e-3
IMAGE_DEFAULT_SIZE=1024x1024
IMAGE_STYLE=vivid

# ===== IOT BRIDGE - Raspberry Pi =====
ENABLE_IOT_BRIDGE=false
RIDER_PI_HOST=localhost
RIDER_PI_PORT=22
RIDER_PI_USERNAME=pi
RIDER_PI_PASSWORD=
RIDER_PI_KEY_FILE=
RIDER_PI_PROTOCOL=ssh
IOT_REQUIRE_CONFIRMATION=true

# ===== THE SIMULACRUM - Simulation Layer =====
ENABLE_SIMULATION=false
SIMULATION_CHAOS_ENABLED=false
SIMULATION_MAX_STEPS=10
SIMULATION_USER_MODEL=local
SIMULATION_ANALYST_MODEL=openai
SIMULATION_DEFAULT_USERS=5
SIMULATION_LOGS_DIR=./workspace/simulation_logs

# ===== DOCKER SANDBOX =====
DOCKER_IMAGE_NAME=python:3.11-slim
ENABLE_SANDBOX=true

# ===== ADVANCED SETTINGS =====
# Prompt Manager
PROMPTS_DIR=./data/prompts

# Token Economist
ENABLE_CONTEXT_COMPRESSION=true
MAX_CONTEXT_TOKENS=4000
DEFAULT_COST_MODEL=gpt-3.5-turbo
TOKEN_COST_ESTIMATION_SPLIT=0.5
NEWS_SUMMARY_MAX_CHARS=240
TRANSLATION_TIMEOUT_NEWS=6.0
TRANSLATION_TIMEOUT_PAPERS=8.0

# Queue Governance
MAX_CONCURRENT_TASKS=5
ENABLE_QUEUE_LIMITS=true

# ONNX Models
MODEL_PHI3_PATH=models/phi3-mini-4k-instruct-onnx
LOCAL_MODEL_PATTERNS=["local","phi","mistral","llama","gemma","qwen"]
VISION_MODEL_NAMES=["llava","vision","moondream","bakllava"]

# ===== STABLE DIFFUSION CONFIGURATION =====
STABLE_DIFFUSION_ENDPOINT=http://127.0.0.1:7860
SD_PING_TIMEOUT=5.0
SD_GENERATION_TIMEOUT=120.0
SD_DEFAULT_STEPS=20
SD_DEFAULT_CFG_SCALE=7.0
SD_DEFAULT_SAMPLER=DPM++ 2M Karras

# ===== AI MODELS NAMES =====
# OpenAI Models
OPENAI_GPT4O_MODEL=gpt-4o
OPENAI_GPT4O_MINI_MODEL=gpt-4o-mini
OPENAI_GPT4_TURBO_MODEL=gpt-4-turbo
OPENAI_GPT35_TURBO_MODEL=gpt-3.5-turbo

# Google Models
GOOGLE_GEMINI_FLASH_MODEL=gemini-1.5-flash
GOOGLE_GEMINI_PRO_MODEL=gemini-1.5-pro
GOOGLE_GEMINI_PRO_LEGACY_MODEL=gemini-pro

# Claude Models
CLAUDE_OPUS_MODEL=claude-opus
CLAUDE_SONNET_MODEL=claude-sonnet

# Local Models
LOCAL_LLAMA3_MODEL=llama3
LOCAL_PHI3_MODEL=phi3:latest

# ===== DOCKER IMAGES =====
DOCKER_CUDA_IMAGE=nvidia/cuda:12.0.0-base-ubuntu22.04
DOCKER_REDIS_IMAGE=redis:7-alpine
DOCKER_NODE_IMAGE=node:18-alpine

# ===== API TIMEOUTS =====
OPENAI_API_TIMEOUT=30.0
LOCAL_VISION_TIMEOUT=60.0
OLLAMA_CHECK_TIMEOUT=2.0
HTTP_REQUEST_TIMEOUT=30.0

# ===== TOKEN ECONOMIST =====
RESERVE_TOKENS_FOR_SUMMARY=500
PRICING_FILE_PATH=./data/config/pricing.yaml

# ===== MODEL ROUTER =====
COST_THRESHOLD_USD=0.01
COMPLEXITY_THRESHOLD_LOCAL=5

# ===== VISION & PERCEPTION =====
MIN_BASE64_LENGTH=500
DEFAULT_VISION_CONFIDENCE=0.7
VISION_MAX_TOKENS=500
VISION_GROUNDING_MAX_TOKENS=100

# ===== API ENDPOINTS =====
OPENAI_CHAT_COMPLETIONS_ENDPOINT=https://api.openai.com/v1/chat/completions

# ===== SYSTEM & MONITORING =====
SYSTEM_SERVICES_ENDPOINT=http://localhost:8000/api/v1/system/services

# ===== FOREMAN (Load Balancer) =====
# Wagi priorytetów dla obliczania obciążenia węzła (suma powinna wynosić 1.0)
FOREMAN_CPU_WEIGHT=0.4
FOREMAN_MEMORY_WEIGHT=0.3
FOREMAN_TASKS_WEIGHT=0.3
# Maksymalna liczba zadań dla normalizacji (10 zadań = 100% obciążenia)
FOREMAN_MAX_TASKS_NORMALIZATION=10

# ===== INTENT CLASSIFICATION & RAG BOOST =====
# Phase A: Intent Embedding Router
ENABLE_INTENT_EMBEDDING_ROUTER=false
INTENT_EMBED_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
INTENT_EMBED_MIN_SCORE=0.62
INTENT_EMBED_MARGIN=0.05

# Phase B: RAG Retrieval Boost (Intent-based context optimization)
ENABLE_RAG_RETRIEVAL_BOOST=false
RAG_BOOST_TOP_K_DEFAULT=5
RAG_BOOST_TOP_K_RESEARCH=8
RAG_BOOST_TOP_K_KNOWLEDGE=8
RAG_BOOST_TOP_K_COMPLEX=6
RAG_BOOST_MAX_HOPS_DEFAULT=2
RAG_BOOST_MAX_HOPS_RESEARCH=3
RAG_BOOST_MAX_HOPS_KNOWLEDGE=3
RAG_BOOST_LESSONS_LIMIT_DEFAULT=3
RAG_BOOST_LESSONS_LIMIT_RESEARCH=5
RAG_BOOST_LESSONS_LIMIT_KNOWLEDGE=5

# Meta-learning
ENABLE_META_LEARNING=true
LESSONS_TTL_DAYS=0
