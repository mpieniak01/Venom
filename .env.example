# ===== VENOM v2.0 Configuration Example =====
# Skopiuj ten plik do .env i uzupełnij wartości

# ===== BASIC CONFIGURATION =====
APP_NAME=Venom Meta-Intelligence
ENV=development

WORKSPACE_ROOT=./workspace
MEMORY_ROOT=./data/memory
STATE_FILE_PATH=./data/memory/state_dump.json

# ===== AI CONFIGURATION (HYBRID ENGINE) =====

# AI Mode: LOCAL (tylko lokalne modele), HYBRID (mix local+cloud), CLOUD (głównie cloud)
AI_MODE=LOCAL

# Local LLM Configuration (Ollama/vLLM/Llama.cpp)
LLM_SERVICE_TYPE=local
LLM_LOCAL_ENDPOINT=http://localhost:11434/v1
LLM_MODEL_NAME=llama3
LLM_LOCAL_API_KEY=venom-local
MODEL_GENERATION_OVERRIDES=
# Strategia streszczeń: llm_with_fallback lub heuristic_only
SUMMARY_STRATEGY=llm_with_fallback

# Cloud Providers (opcjonalne, wymagane dla trybu HYBRID/CLOUD)
GOOGLE_API_KEY=
OPENAI_API_KEY=

# Hybrid Mode Settings
HYBRID_CLOUD_PROVIDER=google
HYBRID_LOCAL_MODEL=llama3
HYBRID_CLOUD_MODEL=gemini-1.5-pro
SENSITIVE_DATA_LOCAL_ONLY=true

# Model Routing
ENABLE_MODEL_ROUTING=true
FORCE_LOCAL_MODEL=false
ENABLE_MULTI_SERVICE=false

# ===== THE HIVE - Distributed Processing =====
# Architektura rozproszona z Redis message broker
ENABLE_HIVE=false
HIVE_URL=
HIVE_REGISTRATION_TOKEN=
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
HIVE_HIGH_PRIORITY_QUEUE=venom:tasks:high
HIVE_BACKGROUND_QUEUE=venom:tasks:background
HIVE_BROADCAST_CHANNEL=venom:broadcast
HIVE_TASK_TIMEOUT=300
HIVE_MAX_RETRIES=3
HIVE_ZOMBIE_TASK_TIMEOUT=600

# ===== THE NEXUS - Distributed Mesh =====
# Master-Worker architecture dla zdalnych węzłów
ENABLE_NEXUS=false
NEXUS_SHARED_TOKEN=
NEXUS_HEARTBEAT_TIMEOUT=60
NEXUS_PORT=8765

# ===== NETWORK & DISCOVERY =====
# mDNS (Zeroconf) dla lokalnej sieci - venom.local
# UWAGA: Cloudflare został usunięty, używamy lokalnego mDNS

# ===== BACKGROUND TASKS =====
VENOM_PAUSE_BACKGROUND_TASKS=false
ENABLE_AUTO_DOCUMENTATION=true
ENABLE_AUTO_GARDENING=true
ENABLE_MEMORY_CONSOLIDATION=false
ENABLE_HEALTH_CHECKS=true
WATCHER_DEBOUNCE_SECONDS=5
IDLE_THRESHOLD_MINUTES=15

# ===== EXTERNAL INTEGRATIONS =====
# HuggingFace Integration (opcjonalne)
ENABLE_HF_INTEGRATION=true
HF_TOKEN=

# GitHub Integration
GITHUB_TOKEN=
GITHUB_REPO_NAME=
ENABLE_ISSUE_POLLING=false
ISSUE_POLLING_INTERVAL_MINUTES=5

# Notifications
DISCORD_WEBHOOK_URL=
SLACK_WEBHOOK_URL=

# Tavily AI Search (opcjonalne, dla lepszej jakości wyszukiwania)
TAVILY_API_KEY=

# Google Calendar Integration (THE_CALENDAR)
ENABLE_GOOGLE_CALENDAR=false
GOOGLE_CALENDAR_CREDENTIALS_PATH=./data/config/google_calendar_credentials.json
GOOGLE_CALENDAR_TOKEN_PATH=./data/config/google_calendar_token.json
# IMPORTANT: VENOM_CALENDAR_ID must be a separate calendar ID, NOT 'primary'
# Create a new calendar in Google Calendar called "Venom Work" and use its ID here
# Safe Layering: read from primary, write ONLY to venom calendar
VENOM_CALENDAR_ID=venom_work_calendar
VENOM_CALENDAR_NAME=Venom Work

# ===== THE SHADOW - Desktop Awareness =====
ENABLE_PROACTIVE_MODE=false
ENABLE_DESKTOP_SENSOR=false
SHADOW_CONFIDENCE_THRESHOLD=0.8
SHADOW_PRIVACY_FILTER=true
SHADOW_CLIPBOARD_MAX_LENGTH=1000
SHADOW_CHECK_INTERVAL=1

# ===== THE GHOST - Visual GUI Automation =====
ENABLE_GHOST_AGENT=false
GHOST_MAX_STEPS=20
GHOST_STEP_DELAY=1.0
GHOST_VERIFICATION_ENABLED=true
GHOST_SAFETY_DELAY=0.5
GHOST_VISION_CONFIDENCE=0.7

# ===== BRAIN / GRAF WIEDZY =====
# Limity do ładowania grafów w /brain (frontend)
NEXT_PUBLIC_KNOWLEDGE_GRAPH_LIMIT=500
NEXT_PUBLIC_MEMORY_GRAPH_LIMIT=100

# ===== THE AVATAR - Audio Interface =====
ENABLE_AUDIO_INTERFACE=false
WHISPER_MODEL_SIZE=base
TTS_MODEL_PATH=
AUDIO_DEVICE=cpu
VAD_THRESHOLD=0.5
SILENCE_DURATION=1.5

# ===== THE ACADEMY - Knowledge Distillation =====
ENABLE_ACADEMY=true
ACADEMY_TRAINING_DIR=./data/training
ACADEMY_MODELS_DIR=./data/models
ACADEMY_MIN_LESSONS=100
ACADEMY_TRAINING_INTERVAL_HOURS=24
ACADEMY_DEFAULT_BASE_MODEL=unsloth/Phi-3-mini-4k-instruct
ACADEMY_LORA_RANK=16
ACADEMY_LEARNING_RATE=2e-4
ACADEMY_NUM_EPOCHS=3
ACADEMY_BATCH_SIZE=4
ACADEMY_MAX_SEQ_LENGTH=2048
ACADEMY_ENABLE_GPU=true
ACADEMY_TRAINING_IMAGE=unsloth/unsloth:latest

# ===== THE DREAMER - Synthetic Experience =====
ENABLE_DREAMING=false
DREAMING_IDLE_THRESHOLD_MINUTES=30
DREAMING_NIGHT_HOURS=2-6
DREAMING_MAX_SCENARIOS=10
DREAMING_CPU_THRESHOLD=0.7
DREAMING_MEMORY_THRESHOLD=0.8
DREAMING_SCENARIO_COMPLEXITY=medium
DREAMING_VALIDATION_STRICT=true
DREAMING_OUTPUT_DIR=./data/synthetic_training
DREAMING_DOCKER_NAMESPACE=venom-dream-worker
DREAMING_PROCESS_PRIORITY=19

# ===== THE CHRONOMANCER - State Management =====
ENABLE_CHRONOS=true
CHRONOS_TIMELINES_DIR=./data/timelines
CHRONOS_AUTO_CHECKPOINT=true
CHRONOS_MAX_CHECKPOINTS_PER_TIMELINE=50
CHRONOS_CHECKPOINT_RETENTION_DAYS=30
CHRONOS_COMPRESS_SNAPSHOTS=true

# ===== THE LAUNCHPAD - Cloud Deployment =====
ENABLE_LAUNCHPAD=false
DEPLOYMENT_SSH_KEY_PATH=
DEPLOYMENT_DEFAULT_USER=root
DEPLOYMENT_TIMEOUT=300
ASSETS_DIR=./workspace/assets
ENABLE_IMAGE_GENERATION=true
IMAGE_GENERATION_SERVICE=placeholder
DALLE_MODEL=dall-e-3
IMAGE_DEFAULT_SIZE=1024x1024
IMAGE_STYLE=vivid

# ===== IOT BRIDGE - Raspberry Pi =====
ENABLE_IOT_BRIDGE=false
RIDER_PI_HOST=192.168.1.100
RIDER_PI_PORT=22
RIDER_PI_USERNAME=pi
RIDER_PI_PASSWORD=
RIDER_PI_KEY_FILE=
RIDER_PI_PROTOCOL=ssh
IOT_REQUIRE_CONFIRMATION=true

# ===== THE SIMULACRUM - Simulation Layer =====
ENABLE_SIMULATION=false
SIMULATION_CHAOS_ENABLED=false
SIMULATION_MAX_STEPS=10
SIMULATION_USER_MODEL=local
SIMULATION_ANALYST_MODEL=openai
SIMULATION_DEFAULT_USERS=5
SIMULATION_LOGS_DIR=./workspace/simulation_logs

# ===== DOCKER SANDBOX =====
DOCKER_IMAGE_NAME=python:3.11-slim
ENABLE_SANDBOX=true

# ===== ADVANCED SETTINGS =====
# Prompt Manager
PROMPTS_DIR=./data/prompts

# Token Economist
ENABLE_CONTEXT_COMPRESSION=true
MAX_CONTEXT_TOKENS=4000

# ONNX Models
MODEL_PHI3_PATH=models/phi3-mini-4k-instruct-onnx

# ===== STABLE DIFFUSION CONFIGURATION =====
STABLE_DIFFUSION_ENDPOINT=http://127.0.0.1:7860
SD_PING_TIMEOUT=5.0
SD_GENERATION_TIMEOUT=120.0
SD_DEFAULT_STEPS=20
SD_DEFAULT_CFG_SCALE=7.0
SD_DEFAULT_SAMPLER=DPM++ 2M Karras

# ===== AI MODELS NAMES =====
# OpenAI Models
OPENAI_GPT4O_MODEL=gpt-4o
OPENAI_GPT4O_MINI_MODEL=gpt-4o-mini
OPENAI_GPT4_TURBO_MODEL=gpt-4-turbo
OPENAI_GPT35_TURBO_MODEL=gpt-3.5-turbo

# Google Models
GOOGLE_GEMINI_FLASH_MODEL=gemini-1.5-flash
GOOGLE_GEMINI_PRO_MODEL=gemini-1.5-pro
GOOGLE_GEMINI_PRO_LEGACY_MODEL=gemini-pro

# Claude Models
CLAUDE_OPUS_MODEL=claude-opus
CLAUDE_SONNET_MODEL=claude-sonnet

# Local Models
LOCAL_LLAMA3_MODEL=llama3
LOCAL_PHI3_MODEL=phi3:latest

# ===== DOCKER IMAGES =====
DOCKER_CUDA_IMAGE=nvidia/cuda:12.0.0-base-ubuntu22.04
DOCKER_REDIS_IMAGE=redis:7-alpine
DOCKER_NODE_IMAGE=node:18-alpine

# ===== API TIMEOUTS =====
OPENAI_API_TIMEOUT=30.0
LOCAL_VISION_TIMEOUT=60.0
OLLAMA_CHECK_TIMEOUT=2.0
HTTP_REQUEST_TIMEOUT=30.0

# ===== TOKEN ECONOMIST =====
RESERVE_TOKENS_FOR_SUMMARY=500
PRICING_FILE_PATH=./data/config/pricing.yaml

# ===== MODEL ROUTER =====
COST_THRESHOLD_USD=0.01
COMPLEXITY_THRESHOLD_LOCAL=5

# ===== VISION & PERCEPTION =====
MIN_BASE64_LENGTH=500
DEFAULT_VISION_CONFIDENCE=0.7
VISION_MAX_TOKENS=500
VISION_GROUNDING_MAX_TOKENS=100

# ===== API ENDPOINTS =====
OPENAI_CHAT_COMPLETIONS_ENDPOINT=https://api.openai.com/v1/chat/completions

# ===== SYSTEM & MONITORING =====
SYSTEM_SERVICES_ENDPOINT=http://localhost:8000/api/v1/system/services

# ===== FOREMAN (Load Balancer) =====
# Wagi priorytetów dla obliczania obciążenia węzła (suma powinna wynosić 1.0)
FOREMAN_CPU_WEIGHT=0.4
FOREMAN_MEMORY_WEIGHT=0.3
FOREMAN_TASKS_WEIGHT=0.3
# Maksymalna liczba zadań dla normalizacji (10 zadań = 100% obciążenia)
FOREMAN_MAX_TASKS_NORMALIZATION=10
