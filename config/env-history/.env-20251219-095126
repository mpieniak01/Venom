# ===== VENOM v2.0 – Local Lightweight Config =====

# ===== BASIC CONFIGURATION =====
APP_NAME=Venom Meta-Intelligence
ENV=development

WORKSPACE_ROOT=./workspace
MEMORY_ROOT=./data/memory
STATE_FILE_PATH=./data/memory/state_dump.json

# ===== AI CONFIGURATION (LOCAL-ONLY) =====
AI_MODE=HYBRID

LLM_SERVICE_TYPE=openai
LLM_LOCAL_ENDPOINT=http://localhost:8001/v1
LLM_MODEL_NAME=gemma-2b-it
LLM_LOCAL_API_KEY=venom-local
# Legacy FastAPI UI (Cockpit/Strategy) – włączone, aby testy porównawcze miały źródło na porcie 8000
SERVE_LEGACY_UI=true
# (Opcjonalnie) Komendy do sterowania lokalnymi serwerami LLM; podaj pełne polecenia powłoki.
# Jeśli zostawisz puste, przyciski start/stop/restart będą niedostępne.
VLLM_MODEL_PATH=models/gemma-2b-it
VLLM_SERVED_MODEL_NAME=models/gemma-2b-it
VLLM_START_COMMAND=bash /home/ubuntu/venom/scripts/llm/vllm_service.sh start
VLLM_STOP_COMMAND=bash /home/ubuntu/venom/scripts/llm/vllm_service.sh stop
VLLM_RESTART_COMMAND=bash /home/ubuntu/venom/scripts/llm/vllm_service.sh restart
OLLAMA_START_COMMAND=bash /home/ubuntu/venom/scripts/llm/ollama_service.sh start
OLLAMA_STOP_COMMAND=bash /home/ubuntu/venom/scripts/llm/ollama_service.sh stop
OLLAMA_RESTART_COMMAND=bash /home/ubuntu/venom/scripts/llm/ollama_service.sh restart

GOOGLE_API_KEY=
OPENAI_API_KEY=

HYBRID_CLOUD_PROVIDER=google
HYBRID_LOCAL_MODEL=gemma-2b-it
HYBRID_CLOUD_MODEL=gemini-1.5-flash
SENSITIVE_DATA_LOCAL_ONLY=true

ENABLE_MODEL_ROUTING=true
FORCE_LOCAL_MODEL=true
ENABLE_MULTI_SERVICE=false

# ===== PROMPTS & CONTEXT =====
PROMPTS_DIR=./data/prompts
ENABLE_CONTEXT_COMPRESSION=true
MAX_CONTEXT_TOKENS=4096

# ===== BACKGROUND TASKS =====
VENOM_PAUSE_BACKGROUND_TASKS=true
ENABLE_AUTO_DOCUMENTATION=false
ENABLE_AUTO_GARDENING=false
ENABLE_MEMORY_CONSOLIDATION=false
ENABLE_HEALTH_CHECKS=false
WATCHER_DEBOUNCE_SECONDS=5
IDLE_THRESHOLD_MINUTES=15

# ===== DISTRIBUTED FEATURES (disabled for local dev) =====
ENABLE_HIVE=false
HIVE_URL=
HIVE_REGISTRATION_TOKEN=
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

ENABLE_NEXUS=false
NEXUS_SHARED_TOKEN=
NEXUS_HEARTBEAT_TIMEOUT=60
NEXUS_PORT=8765

ENABLE_SIMULATION=false
SIMULATION_CHAOS_ENABLED=false
SIMULATION_MAX_STEPS=10
SIMULATION_USER_MODEL=local
SIMULATION_ANALYST_MODEL=local

# ===== EXTERNAL INTEGRATIONS (disabled placeholders) =====
GITHUB_TOKEN=
GITHUB_REPO_NAME=
ENABLE_ISSUE_POLLING=false
ISSUE_POLLING_INTERVAL_MINUTES=5
DISCORD_WEBHOOK_URL=
SLACK_WEBHOOK_URL=

# ===== AUDIO / AVATAR (local defaults) =====
ENABLE_AUDIO_INTERFACE=false
WHISPER_MODEL_SIZE=base
TTS_MODEL_PATH=./data/audio/en_US-lessac-medium.onnx
AUDIO_DEVICE=cpu
VAD_THRESHOLD=0.5
SILENCE_DURATION=1.5

# ===== SHADOW & GHOST =====
ENABLE_PROACTIVE_MODE=false
ENABLE_DESKTOP_SENSOR=false
SHADOW_CONFIDENCE_THRESHOLD=0.8
SHADOW_PRIVACY_FILTER=true
SHADOW_CHECK_INTERVAL=1

ENABLE_GHOST_AGENT=false
GHOST_MAX_STEPS=20
GHOST_STEP_DELAY=1.0
GHOST_VERIFICATION_ENABLED=true
GHOST_SAFETY_DELAY=0.5
GHOST_VISION_CONFIDENCE=0.7

# ===== ACADEMY / MODEL TRAINING =====
ENABLE_ACADEMY=false
ACADEMY_TRAINING_DIR=./data/training
ACADEMY_MODELS_DIR=./data/models
ACADEMY_MIN_LESSONS=200
ACADEMY_TRAINING_INTERVAL_HOURS=24
ACADEMY_DEFAULT_BASE_MODEL=unsloth/Phi-3-mini-4k-instruct
ACADEMY_LORA_RANK=16
ACADEMY_LEARNING_RATE=0.0002
ACADEMY_NUM_EPOCHS=3
ACADEMY_BATCH_SIZE=4
ACADEMY_MAX_SEQ_LENGTH=2048
ACADEMY_ENABLE_GPU=false
ACADEMY_TRAINING_IMAGE=unsloth/unsloth:latest

# ===== AUDIO / IOT / SANDBOX =====
ENABLE_IOT_BRIDGE=false
RIDER_PI_HOST=192.168.1.100
RIDER_PI_PORT=22
RIDER_PI_USERNAME=pi
RIDER_PI_PASSWORD=
RIDER_PI_KEY_FILE=
RIDER_PI_PROTOCOL=ssh
IOT_REQUIRE_CONFIRMATION=true

DOCKER_IMAGE_NAME=python:3.11-slim
ENABLE_SANDBOX=true

# ===== IMAGE GENERATION (disabled local defaults) =====
ENABLE_IMAGE_GENERATION=false
IMAGE_GENERATION_SERVICE=placeholder
DALLE_MODEL=dall-e-3
IMAGE_DEFAULT_SIZE=1024x1024
IMAGE_STYLE=vivid
